{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üîç Importa√ß√£o das Bibliotecas e Leitura do Arquivo CSV\n",
    "Neste passo, vamos importar as bibliotecas necess√°rias e carregar o arquivo CSV para an√°lise.\n",
    "\n"
   ],
   "id": "20c4aba14933e8f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:02.685481Z",
     "start_time": "2025-04-21T20:39:52.384624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Caminho do arquivo CSV\n",
    "caminho_arquivo = 'vendas_modificado.csv'\n",
    "\n",
    "# Leitura do CSV com fallback de encoding corrigido via bytes\n",
    "df = pd.read_csv(caminho_arquivo, encoding='latin1')\n",
    "\n",
    "\n",
    "# Corre√ß√£o de textos com poss√≠vel corrup√ß√£o de UTF-8\n",
    "def corrigir_encoding(texto):\n",
    "    try:\n",
    "        return texto.encode('latin1').decode('utf-8')\n",
    "    except:\n",
    "        return texto\n",
    "\n",
    "\n",
    "# Aplicar em campos textuais princicep\n",
    "for coluna in ['cliente', 'produto', 'vendedor', 'marca', 'cidade', 'estado', 'cep', 'pagamento']:\n",
    "    df[coluna] = df[coluna].astype(str).apply(corrigir_encoding)\n"
   ],
   "id": "a428b005a3587054",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üîç Limpeza de Dados - Tratamento de Data e Hora\n",
    "O objetivo √© garantir que a coluna `data` esteja no formato `YYYY-MM-DD` e a coluna `hora` no formato `HH:MM:SS`.\n",
    "\n",
    "### Passos:\n",
    "1. Converter o campo `data` para o formato `YYYY-MM-DD`.\n",
    "2. Ajustar o campo `hora` para o formato `HH:MM:SS`.\n"
   ],
   "id": "d010ce6e3d26807f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:09.681428Z",
     "start_time": "2025-04-21T20:40:02.736523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Limpeza do campo 'data' para o formato 'YYYY-MM-DD'\n",
    "df['data'] = pd.to_datetime(df['data'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Limpeza do campo 'hora' para o formato 'HH:MM:SS'\n",
    "# Supondo que o formato seja 'HH:MM' ou 'HH:MM:SS'\n",
    "df['hora'] = pd.to_datetime(df['hora'], format='%H:%M:%S', errors='coerce').dt.strftime('%H:%M:%S')\n",
    "\n",
    "# Verificar as primeiras linhas ap√≥s a limpeza\n",
    "df[['data', 'hora']].head()\n"
   ],
   "id": "a1f1b05dff8e5a00",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         data      hora\n",
       "0  2021-03-20  23:35:51\n",
       "1  2020-10-30  09:00:53\n",
       "2  2021-06-09  15:30:28\n",
       "3  2022-06-04  08:41:23\n",
       "4  2019-05-04  13:38:45"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>hora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-20</td>\n",
       "      <td>23:35:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>09:00:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>15:30:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-04</td>\n",
       "      <td>08:41:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>13:38:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# üîç Verificar valores inv√°lidos (NaT) nos campos 'data' e 'hora'\n",
   "id": "b40695d8c5bfc5de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:11.949603Z",
     "start_time": "2025-04-21T20:40:09.861102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reconvertendo os campos para datetime para valida√ß√£o\n",
    "data_invalidas = pd.to_datetime(df['data'], errors='coerce', format='%Y-%m-%d').isna()\n",
    "hora_invalidas = pd.to_datetime(df['hora'], errors='coerce', format='%H:%M:%S').isna()\n",
    "\n",
    "# Total de valores inv√°lidos\n",
    "print(\"üìÖ Datas inv√°lidas:\", data_invalidas.sum())\n",
    "print(\"‚è∞ Horas inv√°lidas:\", hora_invalidas.sum())\n",
    "\n",
    "# (Opcional) Exibir algumas linhas com problemas\n",
    "df[data_invalidas | hora_invalidas][['data', 'hora']].head(10)\n"
   ],
   "id": "a8a2b435428f2184",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Datas inv√°lidas: 0\n",
      "‚è∞ Horas inv√°lidas: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [data, hora]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>hora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üë§ Verifica√ß√£o da coluna `cliente`\n",
    "\n",
    "Nesta etapa, vamos verificar poss√≠veis problemas com os dados de clientes, como:\n",
    "- Valores nulos ou vazios\n",
    "- Espa√ßos desnecess√°rios\n",
    "- Inconsist√™ncias de formata√ß√£o (mai√∫sculas/min√∫sculas)\n",
    "- Registros inv√°lidos ou muito curtos\n"
   ],
   "id": "9b0063b57a5b994b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:12.526141Z",
     "start_time": "2025-04-21T20:40:12.113956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remover espa√ßos desnecess√°rios\n",
    "df['cliente'] = df['cliente'].astype(str).str.strip()\n",
    "\n",
    "# Verificar valores nulos ou vazios\n",
    "clientes_nulos = df['cliente'].isna() | (df['cliente'] == '')\n",
    "print(\"üë§ Clientes vazios ou nulos:\", clientes_nulos.sum())\n",
    "\n",
    "# Verificar nomes curtos (com 2 ou menos caracteres)\n",
    "clientes_curto = df['cliente'].str.len() <= 2\n",
    "print(\"üë§ Clientes com nomes muito curtos (<= 2 caracteres):\", clientes_curto.sum())\n",
    "\n",
    "# Exibir amostra de poss√≠veis problemas\n",
    "df[clientes_nulos | clientes_curto]['cliente'].value_counts().head(10)\n"
   ],
   "id": "bd384b25ac47e10b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ Clientes vazios ou nulos: 0\n",
      "üë§ Clientes com nomes muito curtos (<= 2 caracteres): 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üîç Verifica√ß√£o adicional e normaliza√ß√£o de nomes de clientes\n",
    "\n",
    "Agora, vamos verificar poss√≠veis problemas adicionais, como espa√ßos extras, inconsist√™ncias na capitaliza√ß√£o e duplicatas. Em seguida, vamos normalizar todos os nomes para **letras mai√∫sculas**.\n"
   ],
   "id": "d8dff7664dfaf3a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:13.344533Z",
     "start_time": "2025-04-21T20:40:12.559877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remover espa√ßos extras (in√≠cio e fim)\n",
    "df['cliente'] = df['cliente'].str.strip()\n",
    "\n",
    "# Normalizar para mai√∫sculas\n",
    "df['cliente'] = df['cliente'].str.upper()\n",
    "\n",
    "# Verificar se h√° nomes com n√∫meros ou s√≠mbolos (considerando nomes v√°lidos)\n",
    "# Vamos filtrar apenas se contiver n√∫meros ou caracteres n√£o alfab√©ticos\n",
    "clientes_invalidos = df['cliente'].str.contains(r'[^A-Z\\s√á√Å√â√ç√ì√ö√£√¢√£√°√†]', regex=True)\n",
    "\n",
    "print(\"üö® Clientes com caracteres inv√°lidos:\", clientes_invalidos.sum())\n",
    "\n",
    "# Exibir amostra de clientes inv√°lidos\n",
    "df[clientes_invalidos]['cliente'].drop_duplicates().head(10)\n",
    "\n",
    "# Verificar duplicatas\n",
    "duplicatas = df['cliente'].duplicated().sum()\n",
    "print(f\"üîÅ Total de clientes duplicados: {duplicatas}\")\n"
   ],
   "id": "abec235ec417380b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® Clientes com caracteres inv√°lidos: 53132\n",
      "üîÅ Total de clientes duplicados: 368104\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:14.046405Z",
     "start_time": "2025-04-21T20:40:13.384488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verificar se h√° registros id√™nticos (mesmo cliente, mesmo produto, mesma data e hora)\n",
    "duplicatas_identicas = df.duplicated(subset=['cliente', 'produto', 'data', 'hora'], keep=False)\n",
    "print(f\"üö® Total de registros id√™nticos (mesmo cliente, produto e data/hora): {duplicatas_identicas.sum()}\")\n",
    "\n",
    "# Exibir registros id√™nticos\n",
    "df[duplicatas_identicas].head(20)\n"
   ],
   "id": "5eef474563264ef5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® Total de registros id√™nticos (mesmo cliente, produto e data/hora): 136359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    id_da_compra        data      hora                           cliente  \\\n",
       "0          13679  2021-03-20  23:35:51                 LUCAS ARAUJO KUHN   \n",
       "1          28070  2020-10-30  09:00:53              MICAEL SOUZA RONCETE   \n",
       "4          47123  2019-05-04  13:38:45       GABRIEL MATOS LIMA DA CUNHA   \n",
       "5          38623  2018-02-19  17:32:01       LUCAS ANT√îNIO DE SOUZA NETO   \n",
       "9          10575  2018-10-01  18:36:45         HENRICO DA CUNHA TEIXEIRA   \n",
       "10         43813  2021-06-04  21:07:04         PEDRO MATOS LIMA DA CUNHA   \n",
       "12         10784  2020-07-03  22:34:21               MATEUS VICTOR ALVES   \n",
       "13          1271  2021-04-18  10:56:01       CARLOS ASSIS NOGUEIRA SILVA   \n",
       "15          5650  2021-06-11  14:18:25          VICTOR DA CUNHA TEIXEIRA   \n",
       "17         24847  2022-06-23  12:15:47  THIAGO LACERDA PORTUGAL DA SILVA   \n",
       "18         12051  2020-07-23  15:37:50            ARTHUR FELIPE DE SOUZA   \n",
       "20          7646  2019-03-09  16:49:49             JO√ÉO SILVINO DA SILVA   \n",
       "29         10768  2020-01-02  09:20:41             VICTOR MURATORI DUTRA   \n",
       "31         24476  2020-12-06  04:03:16  THIAGO ANT√îNIO DE DECCO OLIVEIRA   \n",
       "32         48810  2020-12-28  14:17:22  MATEUS ANT√îNIO DE DECCO OLIVEIRA   \n",
       "35         43002  2021-01-20  15:11:26         FELIPE DA SILVA BIANQUINI   \n",
       "36         13465  2020-01-04  13:31:19        MATHEUS GON√áALVES DONADONI   \n",
       "37         37102  2020-08-02  10:32:27             JO√ÉO SILVINO DA SILVA   \n",
       "39         30509  2022-12-09  21:51:13        GUILHERME CASTILHO CARDOSO   \n",
       "41         26966  2019-03-05  18:50:53                VICTOR SILVA RAMOS   \n",
       "\n",
       "             produto     valor  quantidade   total                status  \\\n",
       "0   Queijo Mussarela  R$ 16,87          13  239.31  Pagamento Confirmado   \n",
       "1    Molho de Tomate   R$ 3,25           3    9.75  Pagamento Confirmado   \n",
       "4               Caf√©   R$ 9,48           2   18.96        Em Separa√É¬ß√É¬£o   \n",
       "5               Caf√©  R$ 10,16           1   20.16  Entregue com Sucesso   \n",
       "9           Sabonete   R$ 1,25           2   13.00        Em Separa√É¬ß√É¬£o   \n",
       "10            A√ß√∫car   R$ 3,59           1    3.59  Aguardando Pagamento   \n",
       "12          Manteiga   R$ 6,61           8   71.88         Em Transporte   \n",
       "13   Papel Higi√™nico   R$ 3,89          12   46.68        Em Separa√É¬ß√É¬£o   \n",
       "15              Caf√©   R$ 5,29           1    5.29        Em Separa√É¬ß√É¬£o   \n",
       "17            A√ß√∫car   R$ 3,75           3   24.25        Em Separa√É¬ß√É¬£o   \n",
       "18              Caf√©   R$ 9,45           3   28.35                    AP   \n",
       "20              Caf√©   R$ 5,45           2   10.90        Em Separa√É¬ß√É¬£o   \n",
       "29      √ìleo de Soja   R$ 3,75          10   37.50  Aguardando Pagamento   \n",
       "31            A√ß√∫car   R$ 3,59           1   13.59  Pagamento Confirmado   \n",
       "32            A√ß√∫car   R$ 2,78           3    8.34  Pagamento Confirmado   \n",
       "35             Vinho  R$ 33,33           6  219.98  Aguardando Pagamento   \n",
       "36    Pasta de Dente   R$ 2,79          12   41.48        Em Separa√É¬ß√É¬£o   \n",
       "37           Shampoo   R$ 7,65          12   91.80        Em Separa√É¬ß√É¬£o   \n",
       "39            A√ß√∫car   R$ 2,92           2    5.84        Em Separa√É¬ß√É¬£o   \n",
       "41            A√ß√∫car   R$ 3,13           7   21.91                    AP   \n",
       "\n",
       "                   cidade estado    pais        cep  frete  \\\n",
       "0                 Niter√≥i     RJ  Brasil  24000-000   20.0   \n",
       "1                 Mariana     MG  Brasil  35420-000    0.0   \n",
       "4    Conselheiro Lafaiete     MG  Brasil  36400-000    0.0   \n",
       "5           Resende Costa     MG  Brasil  36340-000   10.0   \n",
       "9        S√£o Jo√£o del-Rei     MG  Brasil  36300-000   10.5   \n",
       "10            S√£o Gon√ßalo     RJ  Brasil  24400-000    0.0   \n",
       "12        Duque de Caxias     RJ  Brasil  25000-000   19.0   \n",
       "13                  Maca√©     RJ  Brasil  27900-000    0.0   \n",
       "15                 Vi√ßosa     MG  Brasil  36570-000    0.0   \n",
       "17           Juiz de Fora     MG  Brasil  36000-000   13.0   \n",
       "18              Guarulhos     SP  Brasil  07000-000    0.0   \n",
       "20               Campinas     SP  Brasil  13000-000    0.0   \n",
       "29                 Muria√©     MG  Brasil  36880-000    0.0   \n",
       "31         Matias Barbosa     MG  Brasil  36120-000   10.0   \n",
       "32             Petr√≥polis     RJ  Brasil  25600-000    0.0   \n",
       "35  Campos dos Goytacazes     RJ  Brasil  28000-000   20.0   \n",
       "36                 Prados     MG  Brasil  36320-000    8.0   \n",
       "37                 Vi√ßosa     MG  Brasil  36570-000    0.0   \n",
       "39                  Bicas     MG  Brasil  36600-000    0.0   \n",
       "41        Duque de Caxias     RJ  Brasil  25000-000    0.0   \n",
       "\n",
       "                 pagamento                            vendedor         marca  \n",
       "0        Cart√£o de Cr√©dito             SAMUEL HENRIQUE CA√áADOR  Porto Alegre  \n",
       "1                      Pix  MICAEL MALAQUIAS DE SOUZA OLIVEIRA        Fugini  \n",
       "4        Cart√£o de Cr√©dito         HENRICO MATOS LIMA DA CUNHA    3 Cora√ß√µes  \n",
       "5   Transfer√™ncia Banc√°ria           VICTOR GON√áALVES DONADONI    3 Cora√ß√µes  \n",
       "9                   Boleto           GABRIEL QUEIROZ DE AGUIAR          Dove  \n",
       "10  Transfer√™ncia Banc√°ria             SAMUEL HENRIQUE CA√áADOR     Caravelas  \n",
       "12             Pix √† Vista             SAMUEL HENRIQUE CA√áADOR        Itamb√©  \n",
       "13  Transfer√™ncia Banc√°ria  MICAEL MALAQUIAS DE SOUZA OLIVEIRA          Neve  \n",
       "15  Transfer√™ncia Banc√°ria  MICAEL MALAQUIAS DE SOUZA OLIVEIRA    3 Cora√ß√µes  \n",
       "17  Transfer√™ncia Banc√°ria             SAMUEL HENRIQUE CA√áADOR     Caravelas  \n",
       "18                  Boleto                HENRICO VICTOR ALVES    3 Cora√ß√µes  \n",
       "20       Cart√£o de Cr√©dito           VICTOR GON√áALVES DONADONI         Pil√£o  \n",
       "29  Transfer√™ncia Banc√°ria            CARLOS QUEIROZ DE AGUIAR         Coamo  \n",
       "31                     Pix                HENRICO VICTOR ALVES     Caravelas  \n",
       "32  Transfer√™ncia Banc√°ria                 PAULO SOUZA RONCETE         Uni√£o  \n",
       "35   Pagamento Instant√¢neo            CARLOS QUEIROZ DE AGUIAR         Miolo  \n",
       "36                     Pix           GABRIEL QUEIROZ DE AGUIAR        Oral-B  \n",
       "37       Cart√£o de Cr√©dito           GABRIEL QUEIROZ DE AGUIAR       Pantene  \n",
       "39       Cart√£o de Cr√©dito                 PAULO SOUZA RONCETE     Itamarati  \n",
       "41  Transfer√™ncia Banc√°ria  MICAEL MALAQUIAS DE SOUZA OLIVEIRA         Uni√£o  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_da_compra</th>\n",
       "      <th>data</th>\n",
       "      <th>hora</th>\n",
       "      <th>cliente</th>\n",
       "      <th>produto</th>\n",
       "      <th>valor</th>\n",
       "      <th>quantidade</th>\n",
       "      <th>total</th>\n",
       "      <th>status</th>\n",
       "      <th>cidade</th>\n",
       "      <th>estado</th>\n",
       "      <th>pais</th>\n",
       "      <th>cep</th>\n",
       "      <th>frete</th>\n",
       "      <th>pagamento</th>\n",
       "      <th>vendedor</th>\n",
       "      <th>marca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13679</td>\n",
       "      <td>2021-03-20</td>\n",
       "      <td>23:35:51</td>\n",
       "      <td>LUCAS ARAUJO KUHN</td>\n",
       "      <td>Queijo Mussarela</td>\n",
       "      <td>R$ 16,87</td>\n",
       "      <td>13</td>\n",
       "      <td>239.31</td>\n",
       "      <td>Pagamento Confirmado</td>\n",
       "      <td>Niter√≥i</td>\n",
       "      <td>RJ</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>24000-000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Cart√£o de Cr√©dito</td>\n",
       "      <td>SAMUEL HENRIQUE CA√áADOR</td>\n",
       "      <td>Porto Alegre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28070</td>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>09:00:53</td>\n",
       "      <td>MICAEL SOUZA RONCETE</td>\n",
       "      <td>Molho de Tomate</td>\n",
       "      <td>R$ 3,25</td>\n",
       "      <td>3</td>\n",
       "      <td>9.75</td>\n",
       "      <td>Pagamento Confirmado</td>\n",
       "      <td>Mariana</td>\n",
       "      <td>MG</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>35420-000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pix</td>\n",
       "      <td>MICAEL MALAQUIAS DE SOUZA OLIVEIRA</td>\n",
       "      <td>Fugini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47123</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>13:38:45</td>\n",
       "      <td>GABRIEL MATOS LIMA DA CUNHA</td>\n",
       "      <td>Caf√©</td>\n",
       "      <td>R$ 9,48</td>\n",
       "      <td>2</td>\n",
       "      <td>18.96</td>\n",
       "      <td>Em Separa√É¬ß√É¬£o</td>\n",
       "      <td>Conselheiro Lafaiete</td>\n",
       "      <td>MG</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>36400-000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cart√£o de Cr√©dito</td>\n",
       "      <td>HENRICO MATOS LIMA DA CUNHA</td>\n",
       "      <td>3 Cora√ß√µes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38623</td>\n",
       "      <td>2018-02-19</td>\n",
       "      <td>17:32:01</td>\n",
       "      <td>LUCAS ANT√îNIO DE SOUZA NETO</td>\n",
       "      <td>Caf√©</td>\n",
       "      <td>R$ 10,16</td>\n",
       "      <td>1</td>\n",
       "      <td>20.16</td>\n",
       "      <td>Entregue com Sucesso</td>\n",
       "      <td>Resende Costa</td>\n",
       "      <td>MG</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>36340-000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Transfer√™ncia Banc√°ria</td>\n",
       "      <td>VICTOR GON√áALVES DONADONI</td>\n",
       "      <td>3 Cora√ß√µes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10575</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>18:36:45</td>\n",
       "      <td>HENRICO DA CUNHA TEIXEIRA</td>\n",
       "      <td>Sabonete</td>\n",
       "      <td>R$ 1,25</td>\n",
       "      <td>2</td>\n",
       "      <td>13.00</td>\n",
       "      <td>Em Separa√É¬ß√É¬£o</td>\n",
       "      <td>S√£o Jo√£o del-Rei</td>\n",
       "      <td>MG</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>36300-000</td>\n",
       "      <td>10.5</td>\n",
       "      <td>Boleto</td>\n",
       "      <td>GABRIEL QUEIROZ DE AGUIAR</td>\n",
       "      <td>Dove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>43813</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>21:07:04</td>\n",
       "      <td>PEDRO MATOS LIMA DA CUNHA</td>\n",
       "      <td>A√ß√∫car</td>\n",
       "      <td>R$ 3,59</td>\n",
       "      <td>1</td>\n",
       "      <td>3.59</td>\n",
       "      <td>Aguardando Pagamento</td>\n",
       "      <td>S√£o Gon√ßalo</td>\n",
       "      <td>RJ</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>24400-000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Transfer√™ncia Banc√°ria</td>\n",
       "      <td>SAMUEL HENRIQUE CA√áADOR</td>\n",
       "      <td>Caravelas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10784</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>22:34:21</td>\n",
       "      <td>MATEUS VICTOR ALVES</td>\n",
       "      <td>Manteiga</td>\n",
       "      <td>R$ 6,61</td>\n",
       "      <td>8</td>\n",
       "      <td>71.88</td>\n",
       "      <td>Em Transporte</td>\n",
       "      <td>Duque de Caxias</td>\n",
       "      <td>RJ</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>25000-000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Pix √† Vista</td>\n",
       "      <td>SAMUEL HENRIQUE CA√áADOR</td>\n",
       "      <td>Itamb√©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1271</td>\n",
       "      <td>2021-04-18</td>\n",
       "      <td>10:56:01</td>\n",
       "      <td>CARLOS ASSIS NOGUEIRA SILVA</td>\n",
       "      <td>Papel Higi√™nico</td>\n",
       "      <td>R$ 3,89</td>\n",
       "      <td>12</td>\n",
       "      <td>46.68</td>\n",
       "      <td>Em Separa√É¬ß√É¬£o</td>\n",
       "      <td>Maca√©</td>\n",
       "      <td>RJ</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>27900-000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Transfer√™ncia Banc√°ria</td>\n",
       "      <td>MICAEL MALAQUIAS DE SOUZA OLIVEIRA</td>\n",
       "      <td>Neve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5650</td>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>14:18:25</td>\n",
       "      <td>VICTOR DA CUNHA TEIXEIRA</td>\n",
       "      <td>Caf√©</td>\n",
       "      <td>R$ 5,29</td>\n",
       "      <td>1</td>\n",
       "      <td>5.29</td>\n",
       "      <td>Em Separa√É¬ß√É¬£o</td>\n",
       "      <td>Vi√ßosa</td>\n",
       "      <td>MG</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>36570-000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Transfer√™ncia Banc√°ria</td>\n",
       "      <td>MICAEL MALAQUIAS DE SOUZA OLIVEIRA</td>\n",
       "      <td>3 Cora√ß√µes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24847</td>\n",
       "      <td>2022-06-23</td>\n",
       "      <td>12:15:47</td>\n",
       "      <td>THIAGO LACERDA PORTUGAL DA SILVA</td>\n",
       "      <td>A√ß√∫car</td>\n",
       "      <td>R$ 3,75</td>\n",
       "      <td>3</td>\n",
       "      <td>24.25</td>\n",
       "      <td>Em Separa√É¬ß√É¬£o</td>\n",
       "      <td>Juiz de Fora</td>\n",
       "      <td>MG</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>36000-000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Transfer√™ncia Banc√°ria</td>\n",
       "      <td>SAMUEL HENRIQUE CA√áADOR</td>\n",
       "      <td>Caravelas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12051</td>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>15:37:50</td>\n",
       "      <td>ARTHUR FELIPE DE SOUZA</td>\n",
       "      <td>Caf√©</td>\n",
       "      <td>R$ 9,45</td>\n",
       "      <td>3</td>\n",
       "      <td>28.35</td>\n",
       "      <td>AP</td>\n",
       "      <td>Guarulhos</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>07000-000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Boleto</td>\n",
       "      <td>HENRICO VICTOR ALVES</td>\n",
       "      <td>3 Cora√ß√µes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7646</td>\n",
       "      <td>2019-03-09</td>\n",
       "      <td>16:49:49</td>\n",
       "      <td>JO√ÉO SILVINO DA SILVA</td>\n",
       "      <td>Caf√©</td>\n",
       "      <td>R$ 5,45</td>\n",
       "      <td>2</td>\n",
       "      <td>10.90</td>\n",
       "      <td>Em Separa√É¬ß√É¬£o</td>\n",
       "      <td>Campinas</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>13000-000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cart√£o de Cr√©dito</td>\n",
       "      <td>VICTOR GON√áALVES DONADONI</td>\n",
       "      <td>Pil√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10768</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>09:20:41</td>\n",
       "      <td>VICTOR MURATORI DUTRA</td>\n",
       "      <td>√ìleo de Soja</td>\n",
       "      <td>R$ 3,75</td>\n",
       "      <td>10</td>\n",
       "      <td>37.50</td>\n",
       "      <td>Aguardando Pagamento</td>\n",
       "      <td>Muria√©</td>\n",
       "      <td>MG</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>36880-000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Transfer√™ncia Banc√°ria</td>\n",
       "      <td>CARLOS QUEIROZ DE AGUIAR</td>\n",
       "      <td>Coamo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>24476</td>\n",
       "      <td>2020-12-06</td>\n",
       "      <td>04:03:16</td>\n",
       "      <td>THIAGO ANT√îNIO DE DECCO OLIVEIRA</td>\n",
       "      <td>A√ß√∫car</td>\n",
       "      <td>R$ 3,59</td>\n",
       "      <td>1</td>\n",
       "      <td>13.59</td>\n",
       "      <td>Pagamento Confirmado</td>\n",
       "      <td>Matias Barbosa</td>\n",
       "      <td>MG</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>36120-000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Pix</td>\n",
       "      <td>HENRICO VICTOR ALVES</td>\n",
       "      <td>Caravelas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>48810</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>14:17:22</td>\n",
       "      <td>MATEUS ANT√îNIO DE DECCO OLIVEIRA</td>\n",
       "      <td>A√ß√∫car</td>\n",
       "      <td>R$ 2,78</td>\n",
       "      <td>3</td>\n",
       "      <td>8.34</td>\n",
       "      <td>Pagamento Confirmado</td>\n",
       "      <td>Petr√≥polis</td>\n",
       "      <td>RJ</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>25600-000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Transfer√™ncia Banc√°ria</td>\n",
       "      <td>PAULO SOUZA RONCETE</td>\n",
       "      <td>Uni√£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>43002</td>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>15:11:26</td>\n",
       "      <td>FELIPE DA SILVA BIANQUINI</td>\n",
       "      <td>Vinho</td>\n",
       "      <td>R$ 33,33</td>\n",
       "      <td>6</td>\n",
       "      <td>219.98</td>\n",
       "      <td>Aguardando Pagamento</td>\n",
       "      <td>Campos dos Goytacazes</td>\n",
       "      <td>RJ</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>28000-000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Pagamento Instant√¢neo</td>\n",
       "      <td>CARLOS QUEIROZ DE AGUIAR</td>\n",
       "      <td>Miolo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>13465</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>13:31:19</td>\n",
       "      <td>MATHEUS GON√áALVES DONADONI</td>\n",
       "      <td>Pasta de Dente</td>\n",
       "      <td>R$ 2,79</td>\n",
       "      <td>12</td>\n",
       "      <td>41.48</td>\n",
       "      <td>Em Separa√É¬ß√É¬£o</td>\n",
       "      <td>Prados</td>\n",
       "      <td>MG</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>36320-000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Pix</td>\n",
       "      <td>GABRIEL QUEIROZ DE AGUIAR</td>\n",
       "      <td>Oral-B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37102</td>\n",
       "      <td>2020-08-02</td>\n",
       "      <td>10:32:27</td>\n",
       "      <td>JO√ÉO SILVINO DA SILVA</td>\n",
       "      <td>Shampoo</td>\n",
       "      <td>R$ 7,65</td>\n",
       "      <td>12</td>\n",
       "      <td>91.80</td>\n",
       "      <td>Em Separa√É¬ß√É¬£o</td>\n",
       "      <td>Vi√ßosa</td>\n",
       "      <td>MG</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>36570-000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cart√£o de Cr√©dito</td>\n",
       "      <td>GABRIEL QUEIROZ DE AGUIAR</td>\n",
       "      <td>Pantene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>30509</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>21:51:13</td>\n",
       "      <td>GUILHERME CASTILHO CARDOSO</td>\n",
       "      <td>A√ß√∫car</td>\n",
       "      <td>R$ 2,92</td>\n",
       "      <td>2</td>\n",
       "      <td>5.84</td>\n",
       "      <td>Em Separa√É¬ß√É¬£o</td>\n",
       "      <td>Bicas</td>\n",
       "      <td>MG</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>36600-000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cart√£o de Cr√©dito</td>\n",
       "      <td>PAULO SOUZA RONCETE</td>\n",
       "      <td>Itamarati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>26966</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>18:50:53</td>\n",
       "      <td>VICTOR SILVA RAMOS</td>\n",
       "      <td>A√ß√∫car</td>\n",
       "      <td>R$ 3,13</td>\n",
       "      <td>7</td>\n",
       "      <td>21.91</td>\n",
       "      <td>AP</td>\n",
       "      <td>Duque de Caxias</td>\n",
       "      <td>RJ</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>25000-000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Transfer√™ncia Banc√°ria</td>\n",
       "      <td>MICAEL MALAQUIAS DE SOUZA OLIVEIRA</td>\n",
       "      <td>Uni√£o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:14.498948Z",
     "start_time": "2025-04-21T20:40:14.246795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convertendo todos os nomes para mai√∫sculas\n",
    "df['cliente'] = df['cliente'].str.upper()\n"
   ],
   "id": "82afd59c5ec65447",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üî¢ Verifica√ß√£o de Formato de Valores Monet√°rios\n",
    "\n",
    "Este c√≥digo verifica se os valores na coluna `valor` est√£o no formato correto de moeda brasileira: \"R$ 10,23\".\n",
    "\n",
    "**Como funciona:**\n",
    "\n",
    "1. **Express√£o Regular**: Utiliza uma regex para garantir que o valor esteja no padr√£o correto.\n",
    "2. **Filtragem de Valores Inv√°lidos**: Identifica os valores que n√£o seguem o formato esperado.\n",
    "3. **Exibi√ß√£o dos Valores Inv√°lidos**: Mostra os primeiros valores fora do padr√£o.\n",
    "\n",
    "O objetivo √© identificar e corrigir valores que n√£o est√£o no formato correto.\n"
   ],
   "id": "1a77bafefc152084"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:17.156642Z",
     "start_time": "2025-04-21T20:40:14.597225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "# Remover espa√ßos em branco extras\n",
    "df['valor'] = df['valor'].str.strip()\n",
    "\n",
    "# Criar uma express√£o regular para verificar o formato esperado \"R$ xx,xx\"\n",
    "pattern = r\"^R\\$\\s\\d{1,3}(\\.\\d{3})*(,\\d{2})?$\"\n",
    "\n",
    "# Verificar quais valores n√£o est√£o no formato esperado\n",
    "invalid_values = df[~df['valor'].str.match(pattern, na=False)]\n",
    "\n",
    "# Mostrar os valores inv√°lidos\n",
    "invalid_values[['valor']].head()\n"
   ],
   "id": "e14dfdeca248d075",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   valor\n",
       "64  R$ 586,8800000000001\n",
       "72               R$ 14,1\n",
       "73                R$ 2,9\n",
       "82                R$ 2,9\n",
       "92               R$ 14,6"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>R$ 586,8800000000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>R$ 14,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>R$ 2,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>R$ 2,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>R$ 14,6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:24.298678Z",
     "start_time": "2025-04-21T20:40:22.987160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Converter a coluna 'valor' para num√©rico ap√≥s limpar o formato\n",
    "df['valor'] = pd.to_numeric(\n",
    "    df['valor'].astype(str)\n",
    "        .str.replace(r'R\\$', '', regex=True)\n",
    "        .str.replace(',', '.'),\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Verificar e reportar os valores n√£o num√©ricos\n",
    "valores_nao_numericos = df['valor'].isna().sum()\n",
    "if valores_nao_numericos > 0:\n",
    "    print(f\"üîç Total de valores n√£o num√©ricos ou n√£o convertidos: {valores_nao_numericos}\")\n",
    "else:\n",
    "    print(\"‚úîÔ∏è Todos os valores foram convertidos com sucesso para num√©rico.\")\n",
    "\n",
    "# C√°lculo dos quartis e IQR\n",
    "Q1 = df['valor'].quantile(0.25)\n",
    "Q3 = df['valor'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Limites para detec√ß√£o de outliers\n",
    "limite_inferior = Q1 - 1.5 * IQR\n",
    "limite_superior = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identificar outliers\n",
    "outliers = df[(df['valor'] < limite_inferior) | (df['valor'] > limite_superior)]\n",
    "if not outliers.empty:\n",
    "    print(\"üö® Outliers encontrados:\")\n",
    "    print(outliers[['valor']].head())\n",
    "else:\n",
    "    print(\"‚úîÔ∏è Nenhum outlier encontrado.\")\n",
    "\n",
    "# Substituir outliers por NaN\n",
    "df.loc[(df['valor'] < limite_inferior) | (df['valor'] > limite_superior), 'valor'] = np.nan\n",
    "\n",
    "# Preencher com a mediana\n",
    "mediana = df['valor'].median()\n",
    "df['valor'] = df['valor'].fillna(mediana)\n",
    "\n",
    "# Exibir resultado final\n",
    "print(\"\\n‚úîÔ∏è Dados tratados (outliers substitu√≠dos pela mediana):\")\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ],
   "id": "d9ae6d0ac81a4c8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Total de valores n√£o num√©ricos ou n√£o convertidos: 83\n",
      "üö® Outliers encontrados:\n",
      "     valor\n",
      "23   30.35\n",
      "35   33.33\n",
      "62   23.89\n",
      "64  586.88\n",
      "99  454.57\n",
      "\n",
      "‚úîÔ∏è Dados tratados (outliers substitu√≠dos pela mediana):\n",
      "   id_da_compra        data      hora                      cliente  \\\n",
      "0         13679  2021-03-20  23:35:51            LUCAS ARAUJO KUHN   \n",
      "1         28070  2020-10-30  09:00:53         MICAEL SOUZA RONCETE   \n",
      "2         47484  2021-06-09  15:30:28    FELIPE AUGUSTO NERY SILVA   \n",
      "3         20809  2022-06-04  08:41:23          LEVI RIBEIRO AMORIM   \n",
      "4         47123  2019-05-04  13:38:45  GABRIEL MATOS LIMA DA CUNHA   \n",
      "\n",
      "            produto  valor  quantidade   total                status  \\\n",
      "0  Queijo Mussarela  16.87          13  239.31  Pagamento Confirmado   \n",
      "1   Molho de Tomate   3.25           3    9.75  Pagamento Confirmado   \n",
      "2      √Ågua Mineral   1.63           9   36.67  Pagamento Confirmado   \n",
      "3            Carv√£o   8.74           4   54.96        Em Separa√É¬ß√É¬£o   \n",
      "4              Caf√©   9.48           2   18.96        Em Separa√É¬ß√É¬£o   \n",
      "\n",
      "                  cidade estado    pais        cep  frete  \\\n",
      "0                Niter√≥i     RJ  Brasil  24000-000   20.0   \n",
      "1                Mariana     MG  Brasil  35420-000    0.0   \n",
      "2              Cabo Frio     RJ  Brasil  28900-000   22.0   \n",
      "3  Campos dos Goytacazes     RJ  Brasil  28000-000   20.0   \n",
      "4   Conselheiro Lafaiete     MG  Brasil  36400-000    0.0   \n",
      "\n",
      "                pagamento                            vendedor         marca  \n",
      "0       Cart√£o de Cr√©dito             SAMUEL HENRIQUE CA√áADOR  Porto Alegre  \n",
      "1                     Pix  MICAEL MALAQUIAS DE SOUZA OLIVEIRA        Fugini  \n",
      "2  Transfer√™ncia Banc√°ria         HENRICO MATOS LIMA DA CUNHA       Minalba  \n",
      "3                     Pix           GABRIEL QUEIROZ DE AGUIAR    Marca-Br√°s  \n",
      "4       Cart√£o de Cr√©dito         HENRICO MATOS LIMA DA CUNHA    3 Cora√ß√µes  \n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:24.528919Z",
     "start_time": "2025-04-21T20:40:24.525614Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "94df565fa33eb4ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üßπ Tratamento da Coluna `valor` e Continuidade do Pr√©-processamento\n",
    "\n",
    "Anteriormente, realizamos um pr√©-processamento na coluna `valor` para garantir a qualidade e consist√™ncia dos dados:\n",
    "\n",
    "- **Convers√£o de dados**: Transformamos a coluna `valor` de texto para o tipo num√©rico (`float`), removendo o s√≠mbolo `R$` e substituindo v√≠rgulas por pontos para padronizar o formato monet√°rio.\n",
    "- **Detec√ß√£o e tratamento de outliers**: Identificamos valores at√≠picos (outliers) usando o m√©todo do IQR (Intervalo Interquart√≠lico) e os substitu√≠mos pela mediana da coluna para evitar distor√ß√µes na an√°lise.\n",
    "- **Tratamento de valores ausentes**: Valores n√£o convertidos foram tratados como `NaN` e preenchidos tamb√©m com a mediana.\n",
    "\n",
    "---\n",
    "\n",
    "Agora, vamos **aplicar o mesmo processo √†s colunas `quantidade`, `total` e `frete`**, pois essas colunas:\n",
    "\n",
    "- Tamb√©m devem estar no formato num√©rico para permitir an√°lises estat√≠sticas e c√°lculos corretos.\n",
    "- Podem conter outliers que afetam a qualidade dos dados.\n",
    "- Precisam estar consistentes para garantir que o campo `total` obede√ßa √† f√≥rmula esperada:\n",
    "\n",
    "```\n",
    "    total = valor * quantidade + frete\n",
    "```\n",
    "\n",
    "Al√©m disso, vamos verificar se **existem valores ausentes** nessas colunas e definir uma estrat√©gia de tratamento adequada (remo√ß√£o ou preenchimento por mediana).\n",
    "\n"
   ],
   "id": "c251b12f3db90bcb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üìã Convers√£o das colunas para float e arredondamento\n",
    "Convertendo as colunas de valor, quantidade, frete e total para float, arredondando com round(2) para padroniza√ß√£o."
   ],
   "id": "f5b8659700e9de57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:27.726608Z",
     "start_time": "2025-04-21T20:40:24.606767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Removendo s√≠mbolos e transformando strings num√©ricas\n",
    "def limpar_valor(col):\n",
    "    return pd.to_numeric(\n",
    "        col.astype(str)\n",
    "           .str.replace(r'R\\$', '', regex=True)\n",
    "           .str.replace(',', '.'),\n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "# Aplicando para as colunas relevantes\n",
    "df['valor'] = limpar_valor(df['valor']).round(2)\n",
    "df['frete'] = limpar_valor(df['frete']).round(2)\n",
    "df['quantidade'] = limpar_valor(df['quantidade']).round(2)\n",
    "df['total'] = limpar_valor(df['total']).round(2)"
   ],
   "id": "8fd21789702cf151",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üß™ Verificando valores faltantes ap√≥s a convers√£o",
   "id": "98c5546307070571"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:27.772103Z",
     "start_time": "2025-04-21T20:40:27.743182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Valores nulos por coluna ap√≥s convers√£o:\")\n",
    "print(df[['valor', 'frete', 'quantidade', 'total']].isna().sum())\n"
   ],
   "id": "43218942913b32d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos por coluna ap√≥s convers√£o:\n",
      "valor            0\n",
      "frete         7371\n",
      "quantidade       0\n",
      "total         3685\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üßπ Tratamento de outliers e negativos no frete\n",
    "Identificando e corrigindo outliers, valores negativos e NaN na coluna frete."
   ],
   "id": "de3fb2b2a2d7d55a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:27.863177Z",
     "start_time": "2025-04-21T20:40:27.825888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Detectando outliers pelo m√©todo IQR\n",
    "Q1 = df['frete'].quantile(0.25)\n",
    "Q3 = df['frete'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "limite_inferior = Q1 - 1.5 * IQR\n",
    "limite_superior = Q3 + 1.5 * IQR\n",
    "\n",
    "# Criando m√°scara de valores problem√°ticos\n",
    "frete_problema = (\n",
    "    (df['frete'] < 0) |\n",
    "    (df['frete'].isna()) |\n",
    "    (df['frete'] < limite_inferior) |\n",
    "    (df['frete'] > limite_superior)\n",
    ")\n",
    "\n",
    "print(f\"Entradas com frete inv√°lido: {frete_problema.sum()}\")\n"
   ],
   "id": "fb6ba31364a2db8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entradas com frete inv√°lido: 14533\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üèôÔ∏è Agrupando frete mais comum por cidade\n",
    "\n"
   ],
   "id": "3ac04ee2f0661da0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:28.202684Z",
     "start_time": "2025-04-21T20:40:27.922742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Obter o frete mais comum por cidade (moda)\n",
    "frete_mais_comum = df[~frete_problema].groupby('cidade')['frete'].agg(lambda x: x.mode().iloc[0])\n",
    "print(\"\\nFretes mais comuns por cidade:\")\n",
    "print(frete_mais_comum)\n"
   ],
   "id": "7410b84e3a512e2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fretes mais comuns por cidade:\n",
      "cidade\n",
      "Angra dos Reis            0.0\n",
      "Astolfo Dutra             0.0\n",
      "Barbacena                12.0\n",
      "Barroso                   0.0\n",
      "Belford Roxo             19.0\n",
      "Belo Horizonte            0.0\n",
      "Bicas                     0.0\n",
      "Cabo Frio                22.0\n",
      "Campinas                  0.0\n",
      "Campos dos Goytacazes     0.0\n",
      "Caranda√≠                  9.0\n",
      "Cataguases                0.0\n",
      "Congonhas                10.5\n",
      "Conselheiro Lafaiete      0.0\n",
      "Coronel Xavier Chaves     0.0\n",
      "Duque de Caxias           0.0\n",
      "Ewbank da C√¢mara          0.0\n",
      "Guarulhos                 0.0\n",
      "Itabora√≠                  0.0\n",
      "Juiz de Fora             13.0\n",
      "Lagoa Dourada            10.0\n",
      "Leopoldina                0.0\n",
      "Lima Duarte               0.0\n",
      "Maca√©                     0.0\n",
      "Mag√©                     18.0\n",
      "Mariana                   0.0\n",
      "Matias Barbosa           10.0\n",
      "Muria√©                    0.0\n",
      "Niter√≥i                   0.0\n",
      "Nova Igua√ßu               0.0\n",
      "Ouro Branco               0.0\n",
      "Ouro Preto               12.5\n",
      "Palma                     0.0\n",
      "Petr√≥polis                0.0\n",
      "Prados                    8.0\n",
      "Resende Costa            10.0\n",
      "Rio de Janeiro           22.0\n",
      "Rit√°polis                 0.0\n",
      "Santana do Garamb√©u       0.0\n",
      "Santo Andr√©               0.0\n",
      "Santos Dumont             0.0\n",
      "Sim√£o Pereira             0.0\n",
      "S√£o Bernardo do Campo     0.0\n",
      "S√£o Gon√ßalo              20.0\n",
      "S√£o Jos√© dos Campos      17.0\n",
      "S√£o Jo√£o Nepomuceno       0.0\n",
      "S√£o Jo√£o de Meriti        0.0\n",
      "S√£o Jo√£o del-Rei          0.0\n",
      "S√£o Paulo                 0.0\n",
      "S√£o Tiago                 0.0\n",
      "S√£o Vicente de Minas      0.0\n",
      "Tiradentes                0.0\n",
      "Tocantins                 8.5\n",
      "Ub√°                       0.0\n",
      "Vi√ßosa                    9.0\n",
      "Volta Redonda             0.0\n",
      "Name: frete, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3e4e0a20e933ce92"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üîÅ Corrigindo fretes inv√°lidos com base na cidade",
   "id": "22eccd45da0c7a14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:35.523304Z",
     "start_time": "2025-04-21T20:40:28.212301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preencher fretes inv√°lidos com a moda por cidade\n",
    "def substituir_frete(row):\n",
    "    if frete_problema.loc[row.name]:\n",
    "        return frete_mais_comum.get(row['cidade'], np.nan)\n",
    "    return row['frete']\n",
    "\n",
    "df['frete'] = df.apply(substituir_frete, axis=1).round(2)\n",
    "\n",
    "print(\"\\n‚úîÔ∏è Fretes corrigidos com base na cidade.\")\n"
   ],
   "id": "84288bfed2c3acb6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úîÔ∏è Fretes corrigidos com base na cidade.\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üìê Verifica√ß√£o da f√≥rmula do total: `total = valor * quantidade + frete`\n",
   "id": "6bac82d921bdecf3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:36.206377Z",
     "start_time": "2025-04-21T20:40:35.542706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculando o total te√≥rico\n",
    "df['total_calculado'] = (df['valor'] * df['quantidade'] + df['frete']).round(2)\n",
    "\n",
    "# Verificando diverg√™ncias\n",
    "inconsistentes = df[df['total'] != df['total_calculado']]\n",
    "print(f\"\\n‚ö†Ô∏è Linhas com total inconsistente: {inconsistentes.shape[0]}\")\n",
    "print(inconsistentes[['valor', 'quantidade', 'frete', 'total', 'total_calculado']].head())\n"
   ],
   "id": "a6ffd39001d1a5ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Linhas com total inconsistente: 31922\n",
      "    valor  quantidade  frete   total  total_calculado\n",
      "23   4.01           3    8.5   99.55            20.53\n",
      "35   4.01           6   20.0  219.98            44.06\n",
      "62   4.01           7    0.0  167.23            28.07\n",
      "64   4.01           6    0.0   26.88            24.06\n",
      "73   2.90          13    0.0   48.70            37.70\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üõ†Ô∏è Corrigindo valores de `total` com base na f√≥rmula\n",
   "id": "894032cd842cbe14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:36.529658Z",
     "start_time": "2025-04-21T20:40:36.258469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['total'] = df['total_calculado']\n",
    "df.drop(columns=['total_calculado'], inplace=True)\n",
    "print(\"\\n‚úîÔ∏è Coluna 'total' corrigida com base na f√≥rmula.\")\n"
   ],
   "id": "4728ac027bb1474d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úîÔ∏è Coluna 'total' corrigida com base na f√≥rmula.\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Limpeza da Coluna `status`\n",
    "\n",
    "Agora, vamos focar na limpeza da coluna `status`. Essa coluna pode conter valores inconsistentes, como espa√ßos extras, varia√ß√µes de mai√∫sculas/min√∫sculas e valores inesperados que precisam ser tratados. O objetivo √© garantir que os dados dessa coluna sejam uniformes e estejam no formato correto para an√°lise e processamento.\n",
    "\n",
    "#### Passos a serem seguidos:\n",
    "\n",
    "1. **Verificar valores √∫nicos**: Vamos listar todos os valores distintos presentes na coluna `status` para identificar inconsist√™ncias.\n",
    "2. **Contagem de valores**: A contagem de frequ√™ncias de cada valor ajudar√° a ver se algum valor aparece de maneira inesperada ou errada.\n",
    "3. **Limpeza dos valores**:\n",
    "   - Removeremos espa√ßos extras que possam estar presentes em torno\n"
   ],
   "id": "bbed58e8ca0f81d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:36.578994Z",
     "start_time": "2025-04-21T20:40:36.539703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verificar todos os valores √∫nicos na coluna 'status'\n",
    "valores_unicos_status = df['status'].unique()\n",
    "\n",
    "# Exibir os valores √∫nicos\n",
    "print(valores_unicos_status)\n"
   ],
   "id": "4a6622f0523e05ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pagamento Confirmado' 'Em Separa√É¬ß√É¬£o' 'Entregue com Sucesso'\n",
      " 'Aguardando Pagamento' 'Em Transporte' 'AP' 'Entregue' 'PC' 'Sep'\n",
      " 'Separando' 'Pgto Confirmado' 'Transp' 'Transportando' 'Entg'\n",
      " 'aguardando pagamento' 'Aguardando Pgto']\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üîç Limpeza e Padroniza√ß√£o da Coluna `status`\n",
    "\n",
    "Agora, vamos proceder com a limpeza e padroniza√ß√£o dos valores da coluna `status`. O objetivo √© garantir que todos os valores estejam consistentes, facilitando a an√°lise dos dados. A coluna cont√©m v√°rias varia√ß√µes de status, incluindo abrevia√ß√µes, erros de codifica√ß√£o e diferen√ßas de mai√∫sculas/min√∫sculas.\n",
    "\n",
    "#### A√ß√µes que ser√£o realizadas:\n",
    "\n",
    "1. **Padroniza√ß√£o de abrevia√ß√µes**: Algumas abrevia√ß√µes, como \"AP\", \"PC\", \"Sep\", \"Transp\" e \"Entg\", s√£o formas curtas de status conhecidos. Vamos substitu√≠-las pelas vers√µes completas e consistentes, como \"Pagamento Confirmado\", \"Separando\", \"Transportando\", etc.\n",
    "\n",
    "2. **Corre√ß√£o de erros de codifica√ß√£o**: O valor \"Em Separa√É¬ß√É¬£o\" cont√©m caracteres corrompidos, provavelmente devido a um problema de codifica√ß√£o de caracteres. Vamos corrigir para \"Em Separa√ß√£o\".\n",
    "\n",
    "3. **Uniformiza√ß√£o de mai√∫sculas e min√∫sculas**: Para evitar discrep√¢ncias como \"Aguardando Pagamento\" e \"aguardando pagamento\", vamos normalizar todos os valores para min√∫sculas.\n",
    "\n",
    "4. **Tratamento de valores ausentes**: Caso existam valores nulos ou faltantes, vamos definir a melhor estrat√©gia, seja removendo os registros ou imputando valores apropriados.\n",
    "\n",
    "Ap√≥s essas modifica√ß√µes, a coluna estar√° mais limpa e padronizada, pronta para an√°lises e relat√≥rios.\n"
   ],
   "id": "314e4321a01dccdc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:37.869196Z",
     "start_time": "2025-04-21T20:40:36.681055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dicion√°rio de mapeamento de abrevia√ß√µes para valores completos\n",
    "\n",
    "status_map = {\n",
    "    'Em Separa√É¬ß√É¬£o' : 'em separa√ß√£o',\n",
    "    'AP' : 'aguardando pagamento',\n",
    "    'Entregue com Sucesso' : 'entregue',\n",
    "    'Sep' : 'em separa√ß√£o',\n",
    "    'PC' : 'pagamento confirmado',\n",
    "    'Separando' : 'em separa√ß√£o',\n",
    "    'Pgto Confirmado' : 'pagamento confirmado',\n",
    "    'Transp' : 'em transporte',\n",
    "    'Transportando': 'em transporte',\n",
    "    'Entg' : 'entregue',\n",
    "    'Aguardando Pgto' : 'aguardando pagamento',\n",
    "}\n",
    "\n",
    "\n",
    "# Substituir as abrevia√ß√µes e corrigir a codifica√ß√£o\n",
    "df['status'] = df['status'].replace(status_map)\n",
    "\n",
    "# Corrigir poss√≠veis problemas com espa√ßos extras\n",
    "df['status'] = df['status'].str.replace(r'\\s+', ' ', regex=True)  # Substitui m√∫ltiplos espa√ßos por um √∫nico\n",
    "\n",
    "# Remover espa√ßos extras antes ou depois dos textos\n",
    "df['status'] = df['status'].str.strip()\n",
    "\n",
    "# Uniformizar os valores para min√∫sculas\n",
    "df['status'] = df['status'].str.lower()\n",
    "\n",
    "# Verificar se h√° valores ausentes (nulos) e trat√°-los\n",
    "df['status'] = df['status'].fillna('n√£o definido')\n",
    "\n",
    "# Verificar o resultado\n",
    "df['status'].value_counts()\n"
   ],
   "id": "6098ff755b27da59",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "em separa√ß√£o            110609\n",
       "pagamento confirmado    109870\n",
       "aguardando pagamento     74938\n",
       "em transporte            36840\n",
       "entregue                 36495\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Tratamento da Coluna `pagamento`\n",
    "\n",
    "Agora, vamos realizar a limpeza e padroniza√ß√£o da coluna `pagamento` para garantir que os valores estejam consistentes e sem erros. O processo ser√° o seguinte:\n",
    "\n",
    "1. **Verificar as Ocorr√™ncias Atuais**:\n",
    "   - Vamos usar `value_counts()` para listar todas as ocorr√™ncias na coluna `pagamento` e verificar se existem abrevia√ß√µes, erros de digita√ß√£o ou valores inconsistentes. Isso nos ajudar√° a identificar se h√° valores como \"boleto\", \"pix\", \"cart√£o\", entre outros, de forma inconsistente ou com varia√ß√µes que precisam ser unificadas.\n",
    "\n",
    "2. **Aplicar Mapeamento de Valores**:\n",
    "   - Iremos mapear os diferentes tipos de pagamento, como \"boleto\", \"pix\", \"cart√£o\", etc., para valores consistentes. Isso inclui corrigir abrevia√ß√µes, erros de digita√ß√£o ou varia√ß√µes de capitaliza√ß√£o. Por exemplo, se houver \"boleto banc√°rio\" e \"boleto\", ambos devem ser mapeados para o mesmo valor.\n",
    "\n",
    "3. **Limpeza de Espa√ßos Extras**:\n",
    "   - Vamos remover espa√ßos extras antes e depois dos valores, e tamb√©m substituir m√∫ltiplos espa√ßos consecutivos por um √∫nico espa√ßo, caso haja algum.\n",
    "\n",
    "4. **Transformar para Min√∫sculas**:\n",
    "   - Para uniformizar a coluna, vamos garantir que todos os valores estejam em min√∫sculas, eliminando discrep√¢ncias relacionadas √† capitaliza√ß√£o, como \"BOLETO\" e \"boleto\", que devem ser tratados da mesma forma.\n",
    "\n",
    "5. **Tratar Valores Ausentes**:\n",
    "   - Se houver valores ausentes (nulos) na coluna `pagamento`, vamos trat√°-los substituindo-os por um valor padr√£o, como 'N√£o Definido' ou 'N√£o Informado', para evitar dados faltantes.\n",
    "\n",
    "6. **Rever os Resultados**:\n",
    "   - Ap√≥s todas as modifica√ß√µes, vamos verificar as ocorr√™ncias novamente para garantir que todos os valores estejam consistentes e que a coluna esteja pronta para an√°lise.\n",
    "\n",
    "Esse processo garantir√° que a coluna `pagamento` tenha dados mais limpos, consistentes e prontos para serem usados em an√°lises e relat√≥rios, al√©m de facilitar a categoriza√ß√£o por tipo de pagamento.\n"
   ],
   "id": "8b74c8ab1774983b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:38.084976Z",
     "start_time": "2025-04-21T20:40:38.041317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verificar as ocorr√™ncias de cada tipo na coluna 'pagamento'\n",
    "df['pagamento'].value_counts()\n"
   ],
   "id": "b30eacec666bb8fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pagamento\n",
       "Cart√£o de Cr√©dito         108459\n",
       "Transfer√™ncia Banc√°ria    106721\n",
       "Pix                       106504\n",
       "Boleto                     36005\n",
       "Pix √† Vista                 1717\n",
       "Cart√£o Cr√©dito √† Vista      1677\n",
       "Pagamento Instant√¢neo       1676\n",
       "Cart√£o Cr√©dito              1647\n",
       "TED                         1633\n",
       "DOC                         1602\n",
       "Boleto √† Vista               593\n",
       "Boleto no Dinheiro           518\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:39.347324Z",
     "start_time": "2025-04-21T20:40:38.203390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dicion√°rio de mapeamento de abrevia√ß√µes para valores completos no campo 'pagamento'\n",
    "pagamento_map = {\n",
    "    'Boleto √† Vista': 'boleto',\n",
    "    'Boleto no Dinheiro': 'boleto',\n",
    "    'Cart√£o Cr√©dito √† Vista': 'cr√©dito √† vista',\n",
    "    'Cart√£o de Cr√©dito': 'cart√£o de cr√©dito',\n",
    "    'TED': 'transfer√™ncia banc√°ria',\n",
    "    'DOC': 'transfer√™ncia banc√°ria',\n",
    "    'Pagamento Instant√¢neo': 'pix',\n",
    "    'Pix √† Vista': 'pix',\n",
    "}\n",
    "\n",
    "# Substituir valores incorretos\n",
    "df['pagamento'] = df['pagamento'].replace(pagamento_map)\n",
    "\n",
    "# Corrigir poss√≠veis problemas com espa√ßos extras\n",
    "df['pagamento'] = df['pagamento'].str.replace(r'\\s+', ' ', regex=True)  # Substitui m√∫ltiplos espa√ßos por um √∫nico\n",
    "\n",
    "# Remover espa√ßos extras antes ou depois dos textos\n",
    "df['pagamento'] = df['pagamento'].str.strip()\n",
    "\n",
    "# Uniformizar os valores para min√∫sculas\n",
    "df['pagamento'] = df['pagamento'].str.lower()\n",
    "\n",
    "# Verificar se h√° valores ausentes (nulos) e trat√°-los\n",
    "df['pagamento'] = df['pagamento'].fillna('n√£o definido')\n",
    "\n",
    "# Verificar o resultado\n",
    "df['pagamento'].value_counts()\n"
   ],
   "id": "c717e09475b39786",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pagamento\n",
       "transfer√™ncia banc√°ria    109956\n",
       "pix                       109897\n",
       "cart√£o de cr√©dito         108459\n",
       "boleto                     37116\n",
       "cr√©dito √† vista             1677\n",
       "cart√£o cr√©dito              1647\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:39.547009Z",
     "start_time": "2025-04-21T20:40:39.441955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verificar valores √∫nicos na coluna de pagamento\n",
    "valores_unicos_pagamento = df['pagamento'].unique()\n",
    "print(\"Valores √∫nicos em 'pagamento':\")\n",
    "print(valores_unicos_pagamento)\n",
    "\n",
    "# Verificar se h√° valores ausentes ou nulos\n",
    "valores_nulos_pagamento = df['pagamento'].isnull().sum()\n",
    "print(f\"Valores nulos na coluna 'pagamento': {valores_nulos_pagamento}\")"
   ],
   "id": "d82c1e48296a8db7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores √∫nicos em 'pagamento':\n",
      "['cart√£o de cr√©dito' 'pix' 'transfer√™ncia banc√°ria' 'boleto'\n",
      " 'cr√©dito √† vista' 'cart√£o cr√©dito']\n",
      "Valores nulos na coluna 'pagamento': 0\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üåç Limpeza e Padroniza√ß√£o da Coluna `estado`\n",
    "\n",
    "Agora iremos realizar a limpeza e padroniza√ß√£o da coluna `estado` do nosso conjunto de dados. O objetivo √© garantir consist√™ncia nos valores representando os estados brasileiros.\n",
    "\n",
    "#### Etapas previstas:\n",
    "1. **Inspe√ß√£o dos valores √∫nicos**: Verificar quais valores diferentes est√£o presentes na coluna `estado`, identificando poss√≠veis erros de digita√ß√£o, abrevia√ß√µes inconsistentes ou valores inv√°lidos.\n",
    "2. **Cria√ß√£o de um dicion√°rio de mapeamento**: Construir um dicion√°rio para padronizar os nomes e siglas dos estados. Por exemplo, transformar \"sp\", \"SP \", \"S√£o Paulo\", etc., em \"SP\".\n",
    "3. **Aplica√ß√£o do mapeamento**: Substituir os valores inconsistentes pelos padronizados, utilizando o dicion√°rio de mapeamento.\n",
    "4. **Tratamento de valores ausentes**: Se houver estados ausentes (`NaN`),\n"
   ],
   "id": "de5c1751857f4dcb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:39.648631Z",
     "start_time": "2025-04-21T20:40:39.612781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verificar valores √∫nicos na coluna de estado\n",
    "valores_unicos_estado = df['estado'].unique()\n",
    "print(\"Valores √∫nicos em 'estado':\")\n",
    "print(valores_unicos_estado)\n",
    "\n",
    "# Verificar se h√° valores ausentes ou nulos\n",
    "valores_nulos_estado = df['estado'].isnull().sum()\n",
    "print(f\"Valores nulos na coluna 'estado': {valores_nulos_estado}\")\n"
   ],
   "id": "9e41478022792961",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores √∫nicos em 'estado':\n",
      "['RJ' 'MG' 'SP' 'MTSa' 'S√£o Paulo' 'RS' 'PR' 'PSC']\n",
      "Valores nulos na coluna 'estado': 0\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:39.866717Z",
     "start_time": "2025-04-21T20:40:39.731363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dicion√°rio de mapeamento para padronizar os estados\n",
    "estado_map = {\n",
    "    'S√£o Paulo': 'SP',\n",
    "    'MTSa': 'MT',\n",
    "    'PSC': 'SC'\n",
    "}\n",
    "\n",
    "# Aplicar o mapeamento\n",
    "df['estado'] = df['estado'].replace(estado_map)\n",
    "\n",
    "# Verificar os valores √∫nicos ap√≥s a substitui√ß√£o\n",
    "df['estado'].unique()\n"
   ],
   "id": "32293ad56208b1ce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RJ', 'MG', 'SP', 'MT', 'RS', 'PR', 'SC'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üèôÔ∏è Conex√£o entre as Colunas 'CEP' e 'Cidade'\n",
    "\n",
    "### Objetivo:\n",
    "O objetivo de realizar uma valida√ß√£o combinada entre as colunas **CEP** e **Cidade** √© garantir que os dados de localiza√ß√£o estejam consistentes, completos e correspondam corretamente entre si. Isso √© crucial para garantir a qualidade e precis√£o dos dados, al√©m de permitir an√°lises e opera√ß√µes futuras sem erros ou inconsist√™ncias.\n",
    "\n",
    "### Por que Validar 'CEP' e 'Cidade' Juntas?\n",
    "\n",
    "1. **Consist√™ncia de Dados**:\n",
    "   - O **CEP** √© um c√≥digo postal utilizado para identificar a localiza√ß√£o geogr√°fica de um endere√ßo, e ele √© diretamente relacionado √† **cidade** em que est√° localizado. Portanto, √© importante que, ao validarmos o **CEP**, tamb√©m verifiquemos se ele corresponde √† cidade associada.\n",
    "   - Se a cidade for v√°lida, mas o **CEP** n√£o corresponder ou estiver em um formato inv√°lido, isso pode indicar um erro nos dados ou uma incoer√™ncia no registro.\n",
    "\n",
    "2. **Garantir Integridade Geogr√°fica**:\n",
    "   - O processo de valida√ß√£o cruzada entre o **CEP** e a **Cidade** permite evitar casos em que o **CEP** esteja registrado para uma cidade inexistente ou errada.\n",
    "   - Tamb√©m ajuda a filtrar entradas onde o **CEP** pode ser incompleto ou mal formatado, assegurando que o formato do **CEP** esteja correto, e que ele perten√ßa √† cidade informada.\n",
    "\n",
    "3. **Preven√ß√£o de Dados Inconsistentes**:\n",
    "   - Ao realizar a valida√ß√£o combinada, evitamos problemas como:\n",
    "     - Cidades com **CEPs** inv√°lidos.\n",
    "     - Cidades n√£o existentes ou mal escritas associadas a **CEPs** reais.\n",
    "     - Dados faltantes, que podem ser preenchidos corretamente se a verifica√ß√£o for feita com base em ambas as colunas.\n",
    "\n",
    "### Como Funciona a Valida√ß√£o Cruzada:\n",
    "\n",
    "1. **Valida√ß√£o da Cidade**:\n",
    "   - A primeira etapa consiste em garantir que o nome da cidade na coluna **cidade** seja v√°lido. Isso envolve verificar se a cidade cont√©m apenas caracteres alfab√©ticos e espa√ßos (evitar n√∫meros, caracteres especiais e valores nulos).\n",
    "   - Caso algum valor da cidade seja inv√°lido (como cidades com n√∫meros ou caracteres n√£o alfab√©ticos), ele ser√° convertido para `NaN`.\n",
    "\n",
    "2. **Valida√ß√£o do CEP**:\n",
    "   - O **CEP** ser√° verificado para garantir que esteja no formato correto (ex: `00000-000`).\n",
    "   - O **CEP** ser√° validado para garantir que ele n√£o contenha valores incompletos, nulos ou inv√°lidos.\n",
    "   - Em paralelo, √© importante que o **CEP** se associe corretamente √† **cidade**, caso haja necessidade de valida√ß√£o geogr√°fica adicional.\n",
    "\n",
    "3. **Valida√ß√£o Combinada**:\n",
    "   - Ap√≥s a verifica√ß√£o individual, ser√° realizada uma an√°lise de consist√™ncia cruzada entre o **CEP** e a **Cidade** para garantir que a cidade associada ao **CEP** seja v√°lida.\n",
    "   - Caso o **CEP** ou a **Cidade** apresentem discrep√¢ncias (como uma cidade que n√£o corresponda a um **CEP** v√°lido ou vice-versa), essas entradas ser√£o marcadas como `NaN` para posterior an√°lise e corre√ß√£o.\n",
    "\n"
   ],
   "id": "cbd080497fd4e8af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:39.959062Z",
     "start_time": "2025-04-21T20:40:39.876250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verificar valores √∫nicos e nulos nas colunas de 'cidade' e 'cep'\n",
    "valores_unicos_cidade = df['cidade'].unique()\n",
    "valores_nulos_cidade = df['cidade'].isnull().sum()\n",
    "\n",
    "valores_unicos_cep = df['cep'].unique()\n",
    "valores_nulos_cep = df['cep'].isnull().sum()\n",
    "\n",
    "# Exibir as informa√ß√µes\n",
    "print(\"Valores √∫nicos em 'cidade':\")\n",
    "print(valores_unicos_cidade)\n",
    "print(f\"Valores nulos na coluna 'cidade': {valores_nulos_cidade}\\n\")\n",
    "\n",
    "print(\"Valores √∫nicos em 'cep':\")\n",
    "print(valores_unicos_cep)\n",
    "print(f\"Valores nulos na coluna 'cep': {valores_nulos_cep}\\n\")\n"
   ],
   "id": "8fad333f86dddcb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores √∫nicos em 'cidade':\n",
      "['Niter√≥i' 'Mariana' 'Cabo Frio' 'Campos dos Goytacazes'\n",
      " 'Conselheiro Lafaiete' 'Resende Costa' 'S√£o Paulo' 'Bicas'\n",
      " 'S√£o Jo√£o del-Rei' 'S√£o Gon√ßalo' 'S√£o Bernardo do Campo'\n",
      " 'Duque de Caxias' 'Maca√©' 'Vi√ßosa' 'Juiz de Fora' 'Guarulhos'\n",
      " 'Matias Barbosa' 'Campinas' 'Barroso' 'Caranda√≠' 'Barbacena' 'Itabora√≠'\n",
      " 'Muria√©' 'Petr√≥polis' 'Ouro Branco' 'Prados' 'Santos Dumont' 'Cataguases'\n",
      " 'S√£o Jo√£o de Meriti' 'Ub√°' 'Palma' 'Sim√£o Pereira' 'Mag√©'\n",
      " 'Ewbank da C√¢mara' 'Santana do Garamb√©u' 'Astolfo Dutra'\n",
      " 'S√£o Jo√£o Nepomuceno' 'Belo Horizonte' 'Tocantins' 'Congonhas'\n",
      " 'S√£o Vicente de Minas' 'Coronel Xavier Chaves' 'Leopoldina'\n",
      " 'Belford Roxo' 'Rit√°polis' 'Lagoa Dourada' 'Rio de Janeiro' 'Nova Igua√ßu'\n",
      " 'S√£o Tiago' 'S√£o Jos√© dos Campos' 'Volta Redonda' 'Lima Duarte'\n",
      " 'Santo Andr√©' 'Tiradentes' 'Ouro Preto' 'Angra dos Reis']\n",
      "Valores nulos na coluna 'cidade': 0\n",
      "\n",
      "Valores √∫nicos em 'cep':\n",
      "['24000-000' '35420-000' '28900-000' '28000-000' '36400-000' '36340-000'\n",
      " '01000-000' '36600-000' '36300-000' '24400-000' '09700-000' '25000-000'\n",
      " '27900-000' '36570-000' '36000-000' '07000-000' '36120-000' '13000-000'\n",
      " '36212-000' '36280-000' '36200-000' '24800-000' '36880-000' '25600-000'\n",
      " '36420-000' '36320-000' '36240-000' '36770-000' '25500-000' '36500-000'\n",
      " '36710-000' '36123-000' '25900-000' '36108-000' '361X8XXX' '366XXXXX'\n",
      " '36196-000' '36780-000' '36680-000' '30000-000' '36510-000' '36415-000'\n",
      " '37370-000' '36330-000' '36700-000' '26100-000' '36335-000' '36345-000'\n",
      " '20000-000' '26000-000' '36350-000' '12200-000' '27200-000' '36140-000'\n",
      " '09000-000' '3677XXXX' '36325XXX' '35400-000' '36345XXX' '36325-000'\n",
      " '23900-000' '3688XXXX' '36123XXX' '3668XXXX' '367XXXXX' '244XXXXX'\n",
      " '2XXXXXXX' 'X9XXXXXX' '25XXXXXX' '13XXXXXX' '36335XXX' '248XXXXX'\n",
      " '3614XXXX' '36415XXX' '3678XXXX' '256XXXXX' '363XXXXX' '365XXXXX'\n",
      " '289XXXXX' '36196XXX' '259XXXXX' '239XXXXX' '3642XXXX' 'X7XXXXXX'\n",
      " '272XXXXX' 'X1XXXXXX' '3651XXXX' '3628XXXX' '354XXXXX' '3633XXXX'\n",
      " '3612XXXX' '3737XXXX' '3671XXXX' '3634XXXX' '122XXXXX' '3542XXXX'\n",
      " '3635XXXX' '28XXXXXX' '24XXXXXX' '3624XXXX' '36XXXXXX' '261XXXXX'\n",
      " '364XXXXX' '362XXXXX' '3XXXXXXX' '3657XXXX' '3632XXXX' '26XXXXXX'\n",
      " '279XXXXX' 'X97XXXXX' '255XXXXX' '36212XXX']\n",
      "Valores nulos na coluna 'cep': 0\n",
      "\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:47.628912Z",
     "start_time": "2025-04-21T20:40:39.990844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Exemplo de dicion√°rio com CEPs v√°lidos para algumas cidades (o mapeamento deve ser mais completo)\n",
    "cidade_para_cep = {\n",
    "    'Niter√≥i': '24000-000',\n",
    "    'Mariana': '35420-000',\n",
    "    'Cabo Frio': '28900-000',\n",
    "    'Campos dos Goytacazes': '28000-000',\n",
    "    'Conselheiro Lafaiete': '36400-970',\n",
    "    'Resende Costa': '36340-000',\n",
    "    'S√£o Paulo': '01000-000',\n",
    "    'Bicas': '36600-032',\n",
    "    'S√£o Jo√£o del-Rei': '36300-001',\n",
    "    'S√£o Gon√ßalo': '24410-000',\n",
    "    'S√£o Bernardo do Campo': '09600-004',\n",
    "    'Duque de Caxias': '25000-000',\n",
    "    'Maca√©': '27975-170',\n",
    "    'Vi√ßosa': '36570-000',\n",
    "    'Juiz de Fora': '36000-000',\n",
    "    'Guarulhos': '07000-000',\n",
    "    'Matias Barbosa': '36120-000',\n",
    "    'Campinas': '13000-000',\n",
    "    'Barroso': '36212-000',\n",
    "    'Caranda√≠': '36280-000',\n",
    "    'Barbacena': '36200-000',\n",
    "    'Itabora√≠': '24800-000',\n",
    "    'Muria√©': '36880-000',\n",
    "    'Petr√≥polis': '25600-000',\n",
    "    'Ouro Branco': '36420-000',\n",
    "    'Prados': '36320-000',\n",
    "    'Santos Dumont': '36240-000',\n",
    "    'Cataguases': '36770-000',\n",
    "    'S√£o Jo√£o de Meriti': '25500-000',\n",
    "    'Ub√°': '36500-000',\n",
    "    'Palma': '36710-000',\n",
    "    'Sim√£o Pereira': '36123-000',\n",
    "    'Mag√©': '25900-000',\n",
    "    'Ewbank da C√¢mara': '36108-000',\n",
    "    'Santana do Garamb√©u': '36146-000',\n",
    "    'Astolfo Dutra': '36780-000',\n",
    "    'S√£o Jo√£o Nepomuceno': '36196-000',\n",
    "    'Belo Horizonte': '30100-000',\n",
    "    'Tocantins': '36680-000',\n",
    "    'Congonhas': '36415-000',\n",
    "    'S√£o Vicente de Minas': '36510-000',\n",
    "    'Coronel Xavier Chaves': '36415-000',\n",
    "    'Leopoldina': '36770-000',\n",
    "    'Belford Roxo': '26100-000',\n",
    "    'Rit√°polis': '36335-000',\n",
    "    'Lagoa Dourada': '36240-000',\n",
    "    'Rio de Janeiro': '20000-000',\n",
    "    'Nova Igua√ßu': '26200-000',\n",
    "    'S√£o Tiago': '36280-000',\n",
    "    'S√£o Jos√© dos Campos': '12200-000',\n",
    "    'Volta Redonda': '27200-000',\n",
    "    'Lima Duarte': '36140-000',\n",
    "    'Santo Andr√©': '09000-000',\n",
    "    'Tiradentes': '36325-000',\n",
    "    'Ouro Preto': '35400-000',\n",
    "    'Angra dos Reis': '23900-000'\n",
    "}\n",
    "\n",
    "# Fun√ß√£o para corrigir CEPs inv√°lidos\n",
    "def corrigir_cep(row):\n",
    "    if 'X' in row['cep'] or len(row['cep']) != 9:\n",
    "        return cidade_para_cep.get(row['cidade'], row['cep'])  # Substitui se a cidade tiver um CEP v√°lido mapeado\n",
    "    return row['cep']\n",
    "\n",
    "# Aplicar a fun√ß√£o ao DataFrame\n",
    "df['cep'] = df.apply(corrigir_cep, axis=1)\n",
    "\n",
    "# Salvar o DataFrame atualizado\n",
    "df.to_csv('vendas_limpo.csv', index=False)\n"
   ],
   "id": "b8657c5e28b7ae10",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:47.713481Z",
     "start_time": "2025-04-21T20:40:47.639203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verificar valores √∫nicos e nulos nas colunas de 'cidade' e 'cep'\n",
    "valores_unicos_cidade = df['cidade'].unique()\n",
    "valores_nulos_cidade = df['cidade'].isnull().sum()\n",
    "\n",
    "valores_unicos_cep = df['cep'].unique()\n",
    "valores_nulos_cep = df['cep'].isnull().sum()\n",
    "\n",
    "# Exibir as informa√ß√µes\n",
    "print(\"Valores √∫nicos em 'cidade':\")\n",
    "print(valores_unicos_cidade)\n",
    "print(f\"Valores nulos na coluna 'cidade': {valores_nulos_cidade}\\n\")\n",
    "\n",
    "print(\"Valores √∫nicos em 'cep':\")\n",
    "print(valores_unicos_cep)\n",
    "print(f\"Valores nulos na coluna 'cep': {valores_nulos_cep}\\n\")\n"
   ],
   "id": "69201f5ef63cc1eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores √∫nicos em 'cidade':\n",
      "['Niter√≥i' 'Mariana' 'Cabo Frio' 'Campos dos Goytacazes'\n",
      " 'Conselheiro Lafaiete' 'Resende Costa' 'S√£o Paulo' 'Bicas'\n",
      " 'S√£o Jo√£o del-Rei' 'S√£o Gon√ßalo' 'S√£o Bernardo do Campo'\n",
      " 'Duque de Caxias' 'Maca√©' 'Vi√ßosa' 'Juiz de Fora' 'Guarulhos'\n",
      " 'Matias Barbosa' 'Campinas' 'Barroso' 'Caranda√≠' 'Barbacena' 'Itabora√≠'\n",
      " 'Muria√©' 'Petr√≥polis' 'Ouro Branco' 'Prados' 'Santos Dumont' 'Cataguases'\n",
      " 'S√£o Jo√£o de Meriti' 'Ub√°' 'Palma' 'Sim√£o Pereira' 'Mag√©'\n",
      " 'Ewbank da C√¢mara' 'Santana do Garamb√©u' 'Astolfo Dutra'\n",
      " 'S√£o Jo√£o Nepomuceno' 'Belo Horizonte' 'Tocantins' 'Congonhas'\n",
      " 'S√£o Vicente de Minas' 'Coronel Xavier Chaves' 'Leopoldina'\n",
      " 'Belford Roxo' 'Rit√°polis' 'Lagoa Dourada' 'Rio de Janeiro' 'Nova Igua√ßu'\n",
      " 'S√£o Tiago' 'S√£o Jos√© dos Campos' 'Volta Redonda' 'Lima Duarte'\n",
      " 'Santo Andr√©' 'Tiradentes' 'Ouro Preto' 'Angra dos Reis']\n",
      "Valores nulos na coluna 'cidade': 0\n",
      "\n",
      "Valores √∫nicos em 'cep':\n",
      "['24000-000' '35420-000' '28900-000' '28000-000' '36400-000' '36340-000'\n",
      " '01000-000' '36600-000' '36300-000' '24400-000' '09700-000' '25000-000'\n",
      " '27900-000' '36570-000' '36000-000' '07000-000' '36120-000' '13000-000'\n",
      " '36212-000' '36280-000' '36200-000' '24800-000' '36880-000' '25600-000'\n",
      " '36420-000' '36320-000' '36240-000' '36770-000' '25500-000' '36500-000'\n",
      " '36710-000' '36123-000' '25900-000' '36108-000' '36600-032' '36196-000'\n",
      " '36780-000' '36680-000' '30000-000' '36510-000' '36415-000' '37370-000'\n",
      " '36330-000' '36700-000' '26100-000' '36335-000' '36345-000' '20000-000'\n",
      " '26000-000' '36350-000' '12200-000' '27200-000' '36140-000' '09000-000'\n",
      " '36325-000' '35400-000' '23900-000' '24410-000' '36300-001' '36146-000'\n",
      " '36400-970' '30100-000' '26200-000' '27975-170' '09600-004']\n",
      "Valores nulos na coluna 'cep': 0\n",
      "\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üìù An√°lise de Produtos e Marcas - Documenta√ß√£o de Processos\n",
    "\n",
    "## üîç Objetivo\n",
    "\n",
    "O objetivo dessa etapa foi realizar uma an√°lise explorat√≥ria na base de dados, com foco em verificar e corrigir valores de produtos e marcas. Tamb√©m foram realizadas verifica√ß√µes para identificar dados faltantes e inconsist√™ncias nos nomes dos produtos. Para isso, foi utilizado um dicion√°rio de corre√ß√µes para garantir que os nomes dos produtos estejam uniformizados.\n",
    "\n",
    "## üõ†Ô∏è Etapas Realizadas\n",
    "\n",
    "### 1. **Verifica√ß√£o de Valores Nulos**\n",
    "Antes de iniciar qualquer an√°lise, √© importante verificar se existem valores nulos na base de dados. Isso ajuda a identificar poss√≠veis problemas de qualidade de dados. Foram realizadas as seguintes verifica√ß√µes:\n",
    "\n",
    "- **Produtos Nulos**: Verificamos quantos produtos est√£o ausentes (`NaN`).\n",
    "- **Marcas Nulas**: Verificamos quantas marcas est√£o ausentes (`NaN`).\n",
    "\n",
    "```python\n",
    "# Verificar valores nulos\n",
    "print(\"üîç Produtos nulos:\", df['produto'].isna().sum())\n",
    "print(\"üîç Marcas nulas:\", df['marca'].isna().sum())\n"
   ],
   "id": "dcece8143ead696d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:47.968478Z",
     "start_time": "2025-04-21T20:40:47.722165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verificar valores nulos\n",
    "print(\"üîç Produtos nulos:\", df['produto'].isna().sum())\n",
    "print(\"üîç Marcas nulas:\", df['marca'].isna().sum())\n",
    "\n",
    "# Verificar valores √∫nicos\n",
    "print(\"\\nüì¶ Produtos √∫nicos:\")\n",
    "print(df['produto'].value_counts())\n",
    "\n",
    "print(\"\\nüè∑Ô∏è Marcas √∫nicas:\")\n",
    "print(df['marca'].value_counts())\n",
    "\n",
    "# Checar por valores estranhos (ex: espa√ßos extras, letras mai√∫sculas/min√∫sculas diferentes)\n",
    "print(\"\\nüîé Valores de 'produto' √∫nicos (ordenados):\")\n",
    "print(sorted(df['produto'].dropna().unique()))\n",
    "\n",
    "print(\"\\nüîé Valores de 'marca' √∫nicos (ordenados):\")\n",
    "print(sorted(df['marca'].dropna().unique()))\n"
   ],
   "id": "75e5582acec175c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Produtos nulos: 0\n",
      "üîç Marcas nulas: 0\n",
      "\n",
      "üì¶ Produtos √∫nicos:\n",
      "produto\n",
      "Pasta de Dente      25710\n",
      "Queijo Mussarela    25634\n",
      "Sabonete            24278\n",
      "Manteiga            23769\n",
      "Caf√©                21916\n",
      "                    ...  \n",
      "Macirr√£o                1\n",
      "Deqergente              1\n",
      "Cafc                    1\n",
      "Queijo Mussarelz        1\n",
      "Deterwente              1\n",
      "Name: count, Length: 99, dtype: int64\n",
      "\n",
      "üè∑Ô∏è Marcas √∫nicas:\n",
      "marca\n",
      "Dove            15224\n",
      "Itamb√©           9553\n",
      "Colgate          8819\n",
      "Porto Alegre     8806\n",
      "Quat√°            8804\n",
      "                ...  \n",
      "Brilhante        1001\n",
      "Tixan             990\n",
      "Gen√©rico          553\n",
      "Marca-Br√°s        515\n",
      "Ki-Brasa          515\n",
      "Name: count, Length: 88, dtype: int64\n",
      "\n",
      "üîé Valores de 'produto' √∫nicos (ordenados):\n",
      "['Amaciante', 'Amaciante#$@!', 'Amaciayte', 'Arroc', 'Arroz', 'Arroz#$@!', 'A√ß√∫car', 'A√ß√∫car#$@!', 'A√ß√∫caz', 'Biscoito Recheado', 'Biscoito Recheado#$@!', 'Biscoitq Recheado', 'Cafc', 'Caff', 'Caft', 'Caf√©', 'Caf√©#$@!', 'Carv√£o', 'Carv√£o#$@!', 'Cerveja', 'Cerveja#$@!', 'Clf√©', 'Cnf√©', 'Condibionador', 'Condicioiador#$@!', 'Condicionador', 'Condicionador#$@!', 'Deqergente', 'Desinfekante', 'Desinfetante', 'Desinfetante#$@!', 'Desinfetanue', 'Detergente', 'Detergente#$@!', 'Deterwente', 'Farinha de Trigo', 'Farinha de Trigo#$@!', 'Farinha de Tripo', 'Feij√£o', 'Feij√£o#$@!', 'Leite Integral', 'Leite Integral#$@!', 'Macarr√£o', 'Macarr√£o#$@!', 'Macawr√£o', 'Macirr√£o', 'Majarr√£o', 'Manteiga', 'Manteiga#$@!', 'Manteigt', 'Molho de Tomate', 'Molho de Tomate#$@!', 'Molmo de Tomate', 'Mopho de Tomate', 'Mqcarr√£o', 'Papel Higi√™nico', 'Papel Higi√™nico#$@!', 'Papel Toalha', 'Papel Toalha#$@!', 'Papel Twalha', 'Papel qoalha', 'Pasta de Dente', 'Pasta de Dente#$@!', 'Presuntd', 'Presunto', 'Presunto#$@!', 'P√£o de Forma', 'P√£o de Forma#$@!', 'Qbeijo Mussarela', 'Queijo Mussarela', 'Queijo Mussarela#$@!', 'Queijo Mussarelz', 'Refrigerante', 'Refrigerante#$@!', 'Refrigkrante', 'Sabonepe', 'Sabonete', 'Sabonete#$@!', 'Sab√£o em P√≥', 'Sab√£o em P√≥#$@!', 'Sal', 'Sal#$@!', 'Scl', 'Shampoo', 'Shampoo#$@!', 'Suco de Laranja', 'Suco de Laranja#$@!', 'Sucoyde Laranja', 'Vinho', 'Vinho#$@!', 'ieij√£o', 'tal', 'zabonete', '√Ågua Mineral', '√Ågua Mineral#$@!', '√Ågua Mineras', '√Ågua Mineual', '√ìleo de Soja', '√ìleo de Soja#$@!']\n",
      "\n",
      "üîé Valores de 'marca' √∫nicos (ordenados):\n",
      "['3 Cora√ß√µes', 'Adria', 'Anaconda', 'Aurora', 'Avia√ß√£o', 'Barilla', 'Bauducco', 'Brahma', 'Brilhante', 'Caldo Bom', 'Camil', 'Caravelas', 'Cisne', 'Coamo', 'Coca-Cola', 'Colgate', 'Concha y Toro', 'Confort', 'Crystal', 'Dafruta', 'Del Valle', 'Dona Benta', 'Dove', 'Downy', 'Dualette', 'Elefante', 'Eleg√™', 'Elite', 'Fanta', 'Fofo', 'Fugini', 'Gen√©rico', 'Guaran√° Ant√°rtica', 'Heineken', 'Itamarati', 'Itamb√©', 'Ki-Brasa', 'Kicaldo', 'Lebre', 'Limpol', 'Liza', 'Lux', 'Lysoform', 'Marca-Br√°s', 'Marinho', 'Melitta', 'Minalba', 'Minuano', 'Miolo', 'Namorado', 'Nestl√©', 'Neve', 'Nivea', 'Nutrella', 'Omo', 'Oral-B', 'Pantene', 'Perdig√£o', 'Personal', 'Pil√£o', 'Pinho Sol', 'Piracanjuba', 'Porto Alegre', 'Prats', 'Predilecta', 'Pullman', 'Qualy', 'Quat√°', 'Renata', 'Sadia', 'Salton', 'Scott', 'Seda', 'Skol', 'Snob', 'Sol', 'Sorriso', 'Soya', 'S√£o Louren√ßo', 'Tio Jo√£o', 'Tirolez', 'Tixan', 'Triunfo', 'Uni√£o', 'Urbano', 'Veja', 'Wickbold', 'Yp√™']\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## An√°lise de Produtos por Marca\n",
    "Queremos entender quantos produtos diferentes existem para cada marca. Para isso, usamos a fun√ß√£o groupby para contar o n√∫mero de produtos √∫nicos por marca."
   ],
   "id": "df0094d41684b6a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:48.122345Z",
     "start_time": "2025-04-21T20:40:47.980270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verificar quantos produtos √∫nicos cada marca tem\n",
    "produtos_por_marca = df.groupby('marca')['produto'].nunique().sort_values(ascending=False)\n",
    "print(\"\\nüìä Produtos √∫nicos por marca:\")\n",
    "print(produtos_por_marca)"
   ],
   "id": "168d9d124e2bf67a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Produtos √∫nicos por marca:\n",
      "marca\n",
      "Dove          7\n",
      "3 Cora√ß√µes    6\n",
      "Pantene       5\n",
      "Itamb√©        5\n",
      "Seda          5\n",
      "             ..\n",
      "Tixan         2\n",
      "Uni√£o         2\n",
      "Urbano        2\n",
      "Veja          2\n",
      "Wickbold      2\n",
      "Name: produto, Length: 88, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üßπ Limpeza de Dados com Dicion√°rio de Corre√ß√µes\n",
    "\n",
    " Durante a an√°lise, encontramos v√°rios erros de digita√ß√£o e varia√ß√µes nos nomes dos produtos. Para corrigir isso de forma eficiente, utilizamos um **dicion√°rio de corre√ß√µes**. O dicion√°rio cont√©m pares de valores, onde as chaves representam os nomes incorretos ou variantes, e os valores correspondem aos nomes corretos dos produtos.\n",
    "\n",
    "### Abaixo, mostramos um exemplo de como os nomes dos produtos foram corrigidos:"
   ],
   "id": "5bad13f4c0fafa10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:51.816111Z",
     "start_time": "2025-04-21T20:40:48.134090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dict_produtos_corrigidos = {\n",
    "    'Cafc': 'Caf√©', 'Caff': 'Caf√©', 'Caft': 'Caf√©', 'Clf√©': 'Caf√©', 'Cnf√©': 'Caf√©',\n",
    "    'Caf√©#$@!': 'Caf√©',\n",
    "\n",
    "    'Qbeijo Mussarela': 'Queijo Mussarela',\n",
    "    'Queijo Mussarelz': 'Queijo Mussarela',\n",
    "    'Queijo Mussarela#$@!': 'Queijo Mussarela',\n",
    "\n",
    "    'zabonete': 'Sabonete', 'Sabonepe': 'Sabonete',\n",
    "    'Sabonete#$@!': 'Sabonete',\n",
    "\n",
    "    'Deqergente': 'Detergente', 'Deterwente': 'Detergente',\n",
    "    'Detergente#$@!': 'Detergente',\n",
    "\n",
    "    'Desinfekante': 'Desinfetante', 'Desinfetanue': 'Desinfetante',\n",
    "    'Desinfetante#$@!': 'Desinfetante',\n",
    "\n",
    "    'Macirr√£o': 'Macarr√£o', 'Macawr√£o': 'Macarr√£o', 'Majarr√£o': 'Macarr√£o', 'Mqcarr√£o': 'Macarr√£o',\n",
    "    'Macarr√£o#$@!': 'Macarr√£o',\n",
    "\n",
    "    'Papel Twalha': 'Papel Toalha', 'Papel qoalha': 'Papel Toalha',\n",
    "    'Papel Toalha#$@!': 'Papel Toalha',\n",
    "\n",
    "    'Condibionador': 'Condicionador', 'Condicioiador#$@!': 'Condicionador', 'Condicionador#$@!': 'Condicionador',\n",
    "\n",
    "    '√Ågua Mineras': '√Ågua Mineral', '√Ågua Mineual': '√Ågua Mineral',\n",
    "    '√Ågua Mineral#$@!': '√Ågua Mineral',\n",
    "\n",
    "    'Arroc': 'Arroz', 'Arroz#$@!': 'Arroz',\n",
    "\n",
    "    'A√ß√∫caz': 'A√ß√∫car', 'A√ß√∫car#$@!': 'A√ß√∫car',\n",
    "\n",
    "    'Vinho#$@!': 'Vinho',\n",
    "\n",
    "    'Shampoo#$@!': 'Shampoo',\n",
    "\n",
    "    'Amaciante#$@!': 'Amaciante', 'Amaciayte': 'Amaciante',\n",
    "\n",
    "    'Scl': 'Sal', 'Sal#$@!': 'Sal',\n",
    "\n",
    "    'Presuntd': 'Presunto', 'Presunto#$@!': 'Presunto',\n",
    "\n",
    "    'Sab√£o em P√≥#$@!': 'Sab√£o em P√≥',\n",
    "    'sab√£o em p√≥': 'Sab√£o em P√≥',\n",
    "\n",
    "    'Leite Integral#$@!': 'Leite Integral',\n",
    "\n",
    "    'ieij√£o': 'Feij√£o', 'Feij√£o#$@!': 'Feij√£o',\n",
    "\n",
    "    'P√£o de Forma#$@!': 'P√£o de Forma',\n",
    "    'p√£o de forma': 'P√£o de Forma',\n",
    "\n",
    "    'Sucoyde Laranja': 'Suco de Laranja', 'Suco de Laranja#$@!': 'Suco de Laranja',\n",
    "    'suco de laranja': 'Suco de Laranja',\n",
    "\n",
    "    'pasta de dente#$@!': 'Pasta de Dente',\n",
    "    'pasta de dente': 'Pasta de Dente',\n",
    "\n",
    "    'manteigt': 'Manteiga',\n",
    "    'manteiga': 'Manteiga',\n",
    "    'manteiga#$@!': 'Manteiga',\n",
    "\n",
    "    'molho de tomate': 'Molho de Tomate',\n",
    "    'Molho de Tomate': 'Molho de Tomate',\n",
    "    'mopho de tomate': 'Molho de Tomate',\n",
    "    'molho de tomate#$@!': 'Molho de Tomate',\n",
    "    'Molho de Tomate#$@!': 'Molho de Tomate',\n",
    "    'molmo de tomate': 'Molho de Tomate',\n",
    "\n",
    "    'refrigerante#$@!': 'Refrigerante',\n",
    "    'refrigkrante': 'Refrigerante',\n",
    "    'cerveja#$@!': 'Cerveja',\n",
    "\n",
    "    'Biscoito Recheado': 'Biscoito Recheado',\n",
    "    'biscoito recheado#$@!': 'Biscoito Recheado',\n",
    "    'Biscoitq Recheado': 'Biscoito Recheado',\n",
    "\n",
    "    '√ìleo de Soja': '√ìleo de Soja',\n",
    "    '√≥leo de soja#$@!': '√ìleo de Soja',\n",
    "\n",
    "    'Farinha de Trigo': 'Farinha de Trigo',\n",
    "    'farinha de trigo#$@!': 'Farinha de Trigo',\n",
    "    'farinha de tripo': 'Farinha de Trigo',\n",
    "\n",
    "    'papel higi√™nico#$@!': 'Papel Higi√™nico',\n",
    "    'carv√£o#$@!': 'Carv√£o',\n",
    "    'tal': 'Talco'\n",
    "}\n",
    "dict_produtos_corrigidos = {k.lower(): v for k, v in dict_produtos_corrigidos.items()}\n",
    "df['produto'] = df['produto'].str.lower()\n",
    "df['produto'] = df['produto'].replace(dict_produtos_corrigidos)\n",
    "df['produto'] = df['produto'].str.title()\n",
    "print(\"üîç Produtos √∫nicos ap√≥s corre√ß√£o:\")\n",
    "print(df['produto'].value_counts())"
   ],
   "id": "e24539aefe0e41f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Produtos √∫nicos ap√≥s corre√ß√£o:\n",
      "produto\n",
      "Pasta De Dente       26250\n",
      "Queijo Mussarela     26161\n",
      "Sabonete             24764\n",
      "Manteiga             24224\n",
      "Caf√©                 22372\n",
      "A√ß√∫car               22150\n",
      "Papel Toalha         18742\n",
      "Desinfetante         18544\n",
      "Molho De Tomate      12546\n",
      "Condicionador        11423\n",
      "Refrigerante          9643\n",
      "√Ågua Mineral          9609\n",
      "Farinha De Trigo      9537\n",
      "Macarr√£o              9529\n",
      "Sal                   9497\n",
      "Biscoito Recheado     9486\n",
      "Presunto              9484\n",
      "Vinho                 9472\n",
      "Detergente            9458\n",
      "Shampoo               9443\n",
      "√ìleo De Soja          9389\n",
      "Suco De Laranja       9261\n",
      "Cerveja               8626\n",
      "P√£o De Forma          6799\n",
      "Feij√£o                6317\n",
      "Arroz                 6279\n",
      "Papel Higi√™nico       5463\n",
      "Amaciante             4972\n",
      "Leite Integral        4730\n",
      "Sab√£o Em P√≥           2998\n",
      "Carv√£o                1583\n",
      "Talco                    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üîç An√°lise e Debug da Coluna `vendedores`\n",
    "\n",
    "Nesta c√©lula, vamos realizar uma an√°lise completa da coluna `vendedores` para identificar:\n",
    "\n",
    "1. **Valores nulos** (`NaN`)\n",
    "2. **Strings vazias** ou compostas apenas por espa√ßos\n",
    "3. **Tipos de dados inconsistentes**\n",
    "4. **Padr√µes inv√°lidos** (por exemplo, entradas num√©ricas, s√≠mbolos ou formata√ß√£o incorreta)\n",
    "5. **Valores √∫nicos** para inspe√ß√£o manual\n",
    "\n",
    "Essas verifica√ß√µes ajudam a garantir a qualidade dos dados antes de qualquer an√°lise ou uso da coluna em modelos.\n"
   ],
   "id": "205fc474d3929bf7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:52.728859Z",
     "start_time": "2025-04-21T20:40:51.845014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# üîç Debug da coluna 'vendedor'\n",
    "\n",
    "# 1. Verificar quantidade de valores nulos\n",
    "nulos = df['vendedor'].isnull().sum()\n",
    "print(f'üü® Valores nulos na coluna \"vendedor\": {nulos}')\n",
    "\n",
    "# 2. Visualizar linhas com valores nulos\n",
    "print(\"\\nüßæ Linhas com valores nulos:\")\n",
    "display(df[df['vendedor'].isnull()])\n",
    "\n",
    "# 3. Verificar valores que s√£o strings vazias ou s√≥ espa√ßos\n",
    "espacos_vazios = df['vendedor'].astype(str).str.strip() == ''\n",
    "print(f'\\n‚ö†Ô∏è Linhas com string vazia ou espa√ßos em branco: {espacos_vazios.sum()}')\n",
    "display(df[espacos_vazios])\n",
    "\n",
    "# 4. Verificar tipos de dados na coluna\n",
    "print(\"\\nüß¨ Tipos de dados encontrados na coluna:\")\n",
    "print(df['vendedor'].apply(type).value_counts())\n",
    "\n",
    "# 5. Verificar padr√µes inv√°lidos (exemplo: algo que n√£o seja apenas letras e espa√ßos)\n",
    "padrao_valido = df['vendedor'].astype(str).str.match(r'^[A-Za-z√Ä-√ø\\s]+$')\n",
    "valores_invalidos = df[~padrao_valido]\n",
    "print(f'\\nüö´ Valores com padr√£o inv√°lido: {valores_invalidos.shape[0]}')\n",
    "display(valores_invalidos)\n",
    "\n",
    "# 6. Exibir valores √∫nicos (para inspe√ß√£o manual)\n",
    "print(\"\\nüîé Valores √∫nicos na coluna\")\n",
    "print(df['vendedor'].unique())\n"
   ],
   "id": "3049e0a15467153f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üü® Valores nulos na coluna \"vendedor\": 0\n",
      "\n",
      "üßæ Linhas com valores nulos:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_da_compra, data, hora, cliente, produto, valor, quantidade, total, status, cidade, estado, pais, cep, frete, pagamento, vendedor, marca]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_da_compra</th>\n",
       "      <th>data</th>\n",
       "      <th>hora</th>\n",
       "      <th>cliente</th>\n",
       "      <th>produto</th>\n",
       "      <th>valor</th>\n",
       "      <th>quantidade</th>\n",
       "      <th>total</th>\n",
       "      <th>status</th>\n",
       "      <th>cidade</th>\n",
       "      <th>estado</th>\n",
       "      <th>pais</th>\n",
       "      <th>cep</th>\n",
       "      <th>frete</th>\n",
       "      <th>pagamento</th>\n",
       "      <th>vendedor</th>\n",
       "      <th>marca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Linhas com string vazia ou espa√ßos em branco: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_da_compra, data, hora, cliente, produto, valor, quantidade, total, status, cidade, estado, pais, cep, frete, pagamento, vendedor, marca]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_da_compra</th>\n",
       "      <th>data</th>\n",
       "      <th>hora</th>\n",
       "      <th>cliente</th>\n",
       "      <th>produto</th>\n",
       "      <th>valor</th>\n",
       "      <th>quantidade</th>\n",
       "      <th>total</th>\n",
       "      <th>status</th>\n",
       "      <th>cidade</th>\n",
       "      <th>estado</th>\n",
       "      <th>pais</th>\n",
       "      <th>cep</th>\n",
       "      <th>frete</th>\n",
       "      <th>pagamento</th>\n",
       "      <th>vendedor</th>\n",
       "      <th>marca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß¨ Tipos de dados encontrados na coluna:\n",
      "vendedor\n",
      "<class 'str'>    368752\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üö´ Valores com padr√£o inv√°lido: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_da_compra, data, hora, cliente, produto, valor, quantidade, total, status, cidade, estado, pais, cep, frete, pagamento, vendedor, marca]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_da_compra</th>\n",
       "      <th>data</th>\n",
       "      <th>hora</th>\n",
       "      <th>cliente</th>\n",
       "      <th>produto</th>\n",
       "      <th>valor</th>\n",
       "      <th>quantidade</th>\n",
       "      <th>total</th>\n",
       "      <th>status</th>\n",
       "      <th>cidade</th>\n",
       "      <th>estado</th>\n",
       "      <th>pais</th>\n",
       "      <th>cep</th>\n",
       "      <th>frete</th>\n",
       "      <th>pagamento</th>\n",
       "      <th>vendedor</th>\n",
       "      <th>marca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Valores √∫nicos na coluna\n",
      "['SAMUEL HENRIQUE CA√áADOR' 'MICAEL MALAQUIAS DE SOUZA OLIVEIRA'\n",
      " 'HENRICO MATOS LIMA DA CUNHA' 'GABRIEL QUEIROZ DE AGUIAR'\n",
      " 'VICTOR GON√áALVES DONADONI' 'FELIPE HENRIQUE COSTA BARNABE MARAZO'\n",
      " 'HENRICO VICTOR ALVES' 'CARLOS QUEIROZ DE AGUIAR'\n",
      " 'LUCAS VITOR FA√áANHA NEVES' 'PAULO SOUZA RONCETE' 'nan']\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ‚úÖ Conclus√£o da An√°lise da Coluna `vendedor`\n",
    "\n",
    "Bom, como n√£o encontramos erros estruturais na coluna `vendedor`, aqui est√° o resumo:\n",
    "\n",
    "- üü® **Valores nulos reais** (`NaN`): 0\n",
    "- ‚ö†Ô∏è **Strings vazias ou compostas apenas por espa√ßos**: 0\n",
    "- üö´ **Padr√µes inv√°lidos (ex: n√∫meros ou s√≠mbolos)**: 0\n",
    "- üß¨ **Todos os dados s√£o do tipo `str`**\n",
    "- üîé **Valores √∫nicos verificados mostram um caso suspeito: `'nan'` (string)**\n",
    "\n",
    "Embora n√£o seja um `NaN` real, o valor `'nan'` √© sem√¢ntico e logicamente inv√°lido, provavelmente resultado de uma convers√£o ou importa√ß√£o mal interpretada.\n",
    "\n",
    "A seguir, vamos tratar esse caso espec√≠fico substituindo `'nan'` (como string) por `np.nan`, para ser tratado corretamente em opera√ß√µes futuras.\n"
   ],
   "id": "875b3e8ada537cda"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:40:53.220563Z",
     "start_time": "2025-04-21T20:40:53.031660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# üéØ Substituir valores 'nan' (como string) por np.nan\n",
    "df['vendedor'] = df['vendedor'].replace('nan', np.nan)\n",
    "\n",
    "# Verificar novamente ap√≥s substitui√ß√£o\n",
    "nulos_corrigidos = df['vendedor'].isnull().sum()\n",
    "print(f'‚úÖ Ap√≥s corre√ß√£o, valores nulos na coluna \"vendedor\": {nulos_corrigidos}')\n"
   ],
   "id": "4702be4a4d16906d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ap√≥s corre√ß√£o, valores nulos na coluna \"vendedor\": 3680\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üí° Exemplo de l√≥gica para preenchimento:\n",
    "* Ideia 1 : Se o mesmo cliente comprou o mesmo produto na mesma data, e em outra linha o vendedor est√° preenchido, podemos usar esse dado.\n",
    "\n",
    "* Ideia 2: Se uma combina√ß√£o de produto, marca e cidade sempre aparece com o mesmo vendedor, podemos assumir esse vendedor para os nulos."
   ],
   "id": "2adcd9f5d0af5b7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:41:07.156219Z",
     "start_time": "2025-04-21T20:40:53.407024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Primeiro, vamos ver quantas linhas t√™m vendedor == NaN (ap√≥s a limpeza anterior)\n",
    "faltando = df[df['vendedor'].isna()]\n",
    "print(f\"üîé Linhas com vendedor faltando: {faltando.shape[0]}\")\n",
    "\n",
    "# Exemplo: tentar preencher usando cliente + produto como chave\n",
    "# Criamos um mapeamento de pares cliente-produto com vendedor conhecido\n",
    "mapeamento = (\n",
    "    df[df['vendedor'].notna()]\n",
    "    .groupby(['cliente', 'produto'])['vendedor']\n",
    "    .agg(lambda x: x.mode()[0] if not x.mode().empty else np.nan)\n",
    ")\n",
    "\n",
    "# Aplicar esse mapeamento para preencher os nulos\n",
    "def preencher_vendedor(row):\n",
    "    if pd.isna(row['vendedor']):\n",
    "        return mapeamento.get((row['cliente'], row['produto']), np.nan)\n",
    "    return row['vendedor']\n",
    "\n",
    "df['vendedor'] = df.apply(preencher_vendedor, axis=1)\n",
    "\n",
    "# Verificar quantos ainda ficaram sem valor\n",
    "faltando_apos = df['vendedor'].isnull().sum()\n",
    "print(f\"‚úÖ Linhas com vendedor ainda faltando ap√≥s tentativa de preenchimento: {faltando_apos}\")\n"
   ],
   "id": "e220d65566f83dc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Linhas com vendedor faltando: 3680\n",
      "‚úÖ Linhas com vendedor ainda faltando ap√≥s tentativa de preenchimento: 4\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:41:07.859200Z",
     "start_time": "2025-04-21T20:41:07.172086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remover as linhas com vendedor ainda faltando\n",
    "df = df[df['vendedor'].notna()].reset_index(drop=True)\n",
    "\n",
    "print(f\"‚úÖ Base final sem valores nulos em 'vendedor': {df.shape[0]} linhas\")\n"
   ],
   "id": "8119a706ddb9292e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Base final sem valores nulos em 'vendedor': 368748 linhas\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:44:49.513783Z",
     "start_time": "2025-04-21T20:44:39.773851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Normalizando o texto da coluna 'produto' para evitar inconsist√™ncias\n",
    "df['produto'] = df['produto'].str.strip().str.lower()\n",
    "\n",
    "# Removendo o item 'talco' da an√°lise\n",
    "if (df['produto'] == 'talco').sum() == 1:\n",
    "    df = df[df['produto'] != 'talco']\n",
    "    print(\"‚úÖ Produto 'talco' removido com sucesso.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Produto 'talco' aparece mais de uma vez.\")"
   ],
   "id": "e5575136649cd109",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Produto 'talco' removido com sucesso.\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:45:28.195884Z",
     "start_time": "2025-04-21T20:45:22.284859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.to_csv('vendas_limpo.csv', index=False)\n",
    "print(\"‚úÖ Arquivo salvo como 'vendas_limpos.csv'\")\n"
   ],
   "id": "257cf96657dd9594",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Arquivo salvo como 'vendas_limpos.csv'\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T20:48:00.947934Z",
     "start_time": "2025-04-21T20:47:40.513959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "\n",
    "# üßπ Garante que est√° trabalhando com uma c√≥pia segura do DataFrame\n",
    "df = df.copy()\n",
    "\n",
    "# üß© Cria uma nova coluna com Produto + Pagamento\n",
    "df.loc[:, 'item'] = df['produto'].astype(str).str.strip() + ' | ' + df['pagamento'].astype(str).str.strip()\n",
    "\n",
    "# üõí Agrupa por compra (id_da_compra), gerando listas de itens por transa√ß√£o\n",
    "transacoes = df.groupby('id_da_compra')['item'].apply(list).tolist()\n",
    "\n",
    "# üîÑ Transforma as transa√ß√µes para formato bin√°rio (necess√°rio para FP-Growth)\n",
    "te = TransactionEncoder()\n",
    "df_bin = pd.DataFrame(te.fit(transacoes).transform(transacoes), columns=te.columns_)\n",
    "\n",
    "# ‚õèÔ∏è Executa FP-Growth para encontrar conjuntos frequentes\n",
    "frequentes = fpgrowth(df_bin, min_support=0.02, use_colnames=True)\n",
    "\n",
    "# üîó Gera regras de associa√ß√£o com confian√ßa m√≠nima de 50%\n",
    "regras = association_rules(frequentes, metric=\"confidence\", min_threshold=0.5)\n",
    "\n",
    "# üîç Exibe as 10 regras com maior lift (maior poder de associa√ß√£o)\n",
    "regras_ordenadas = regras[['antecedents', 'consequents', 'support', 'confidence', 'lift']].sort_values(by='lift', ascending=False)\n",
    "\n",
    "# üëÅÔ∏è Mostra os resultados\n",
    "print(regras_ordenadas.head(10))\n"
   ],
   "id": "f6d3533f487726e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   antecedents  \\\n",
      "10     (refrigerante | transfer√™ncia banc√°ria)   \n",
      "11  (suco de laranja | transfer√™ncia banc√°ria)   \n",
      "7                         (refrigerante | pix)   \n",
      "8                      (suco de laranja | pix)   \n",
      "13          (desinfetante | cart√£o de cr√©dito)   \n",
      "12          (papel toalha | cart√£o de cr√©dito)   \n",
      "31                        (desinfetante | pix)   \n",
      "30                        (papel toalha | pix)   \n",
      "33     (papel toalha | transfer√™ncia banc√°ria)   \n",
      "32     (desinfetante | transfer√™ncia banc√°ria)   \n",
      "\n",
      "                                   consequents   support  confidence  \\\n",
      "10  (suco de laranja | transfer√™ncia banc√°ria)  0.020683    0.552538   \n",
      "11     (refrigerante | transfer√™ncia banc√°ria)  0.020683    0.570575   \n",
      "7                      (suco de laranja | pix)  0.021567    0.560659   \n",
      "8                         (refrigerante | pix)  0.021567    0.575111   \n",
      "13          (papel toalha | cart√£o de cr√©dito)  0.039817    0.625065   \n",
      "12          (desinfetante | cart√£o de cr√©dito)  0.039817    0.622297   \n",
      "31                        (papel toalha | pix)  0.041517    0.640525   \n",
      "30                        (desinfetante | pix)  0.041517    0.626509   \n",
      "33     (desinfetante | transfer√™ncia banc√°ria)  0.041667    0.630199   \n",
      "32     (papel toalha | transfer√™ncia banc√°ria)  0.041667    0.638570   \n",
      "\n",
      "         lift  \n",
      "10  15.242423  \n",
      "11  15.242423  \n",
      "7   14.950895  \n",
      "8   14.950895  \n",
      "13   9.769191  \n",
      "12   9.769191  \n",
      "31   9.665864  \n",
      "30   9.665864  \n",
      "33   9.658224  \n",
      "32   9.658224  \n"
     ]
    }
   ],
   "execution_count": 69
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
